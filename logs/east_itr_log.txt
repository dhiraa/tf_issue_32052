WARNING: Logging before flag parsing goes to stderr.
E0903 09:52:37.860500 140467900426048 print_helper.py:68] [31m{'delete': True, 'mode': 'test_iterator', 'dataset': 'east', 'num_tfrecord_files': '6'}[0m
I0903 09:52:38.209369 140467900426048 print_helper.py:59] [92mDeleting old data files[0m
  0%|          | 0/6 [00:00<?, ?it/s] 17%|â–ˆâ–‹        | 1/6 [00:01<00:08,  1.72s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:03<00:06,  1.74s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:05<00:05,  1.75s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:07<00:03,  1.76s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:08<00:01,  1.77s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:10<00:00,  1.78s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.78s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.80s/it]2019-09-03 09:52:53.972688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-09-03 09:52:53.992616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:53.993351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-09-03 09:52:53.993514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 09:52:53.994320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-09-03 09:52:53.994981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-09-03 09:52:53.995161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-09-03 09:52:53.996008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-09-03 09:52:53.996628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-09-03 09:52:53.998795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-09-03 09:52:53.998937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.000098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.000652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-09-03 09:52:54.001273: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-03 09:52:54.023935: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-09-03 09:52:54.025095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ddafdc6a70 executing computations on platform Host. Devices:
2019-09-03 09:52:54.025133: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-09-03 09:52:54.096723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.097222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ddafd8b140 executing computations on platform CUDA. Devices:
2019-09-03 09:52:54.097238: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1060 with Max-Q Design, Compute Capability 6.1
2019-09-03 09:52:54.097379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.097759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-09-03 09:52:54.097795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 09:52:54.097813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-09-03 09:52:54.097830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-09-03 09:52:54.097846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-09-03 09:52:54.097863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-09-03 09:52:54.097879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-09-03 09:52:54.097897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-09-03 09:52:54.097943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.098650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.099013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-09-03 09:52:54.099041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 09:52:54.099971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-03 09:52:54.099982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-09-03 09:52:54.099989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-09-03 09:52:54.100178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.100580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 09:52:54.100963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5186 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)

W0903 09:52:54.637929 140467900426048 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0903 09:53:14.369531 140467900426048 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fc0a6bb5e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 147>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
Writing to /opt/tf_issue_32052/data/train_data_img/0.tfrecords
Writing to /opt/tf_issue_32052/data/train_data_img/1.tfrecords
Writing to /opt/tf_issue_32052/data/train_data_img/2.tfrecords
Writing to /opt/tf_issue_32052/data/train_data_img/3.tfrecords
Writing to /opt/tf_issue_32052/data/train_data_img/4.tfrecords
Writing to /opt/tf_issue_32052/data/train_data_img/5.tfrecords
Writing to /opt/tf_issue_32052/data/val_data_img/0.tfrecords
Writing to /opt/tf_issue_32052/data/val_data_img/1.tfrecords
Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
   142    304.0 MiB    304.0 MiB   @profile
   143                             def gen_data(number_files,
   144                                          IS_EAST_IMAGE_TEST,
   145                                          TRAIN_DATA,
   146                                          VAL_DATA,
   147                                          NUM_SAMPLES_PER_FILE,
   148                                          NUM_FEATURES=None):
   149    304.0 MiB      0.0 MiB       if IS_EAST_IMAGE_TEST:
   150    304.0 MiB      0.0 MiB           generate_image_tf_records(number_files=number_files,
   151    304.0 MiB      0.0 MiB                                     out_dir=TRAIN_DATA,
   152    310.9 MiB      6.9 MiB                                     NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)
   153    310.9 MiB      0.0 MiB           generate_image_tf_records(number_files=2, #TODO Fixed?
   154    310.9 MiB      0.0 MiB                                     out_dir=VAL_DATA,
   155    315.8 MiB      4.9 MiB                                     NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)
   156                                 else:
   157                                     generate_numpy_tf_records(number_files=number_files,
   158                                                               out_dir=TRAIN_DATA,
   159                                                               NUM_FEATURES=NUM_FEATURES,
   160                                                               NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)
   161                                     generate_numpy_tf_records(number_files=2, #TODO fixed?
   162                                                               out_dir=VAL_DATA,
   163                                                               NUM_FEATURES=NUM_FEATURES,
   164                                                               NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)


objgraph growth list start
function                         63331    +63331
dict                             34716    +34716
tuple                            31286    +31286
list                             16026    +16026
cell                             14478    +14478
weakref                           9878     +9878
type                              6925     +6925
getset_descriptor                 6505     +6505
property                          4967     +4967
builtin_function_or_method        3889     +3889
ModuleSpec                        3451     +3451
module                            3448     +3448
wrapper_descriptor                3350     +3350
SourceFileLoader                  3206     +3206
method_descriptor                 3152     +3152
set                               2682     +2682
TFDecorator                       1729     +1729
frozenset                         1543     +1543
ArgSpec                           1224     +1224
_OpInfo                           1224     +1224
method                            1174     +1174
classmethod                       1168     +1168
staticmethod                      1099     +1099
member_descriptor                  944      +944
TagMap                             803      +803
cython_function_or_method          608      +608
fused_cython_function              571      +571
ABCMeta                            562      +562
GeneratedProtocolMessageType       505      +505
MovedAttribute                     496      +496
FileFinder                         463      +463
vectorize                          454      +454
Parameter                          452      +452
NamedTypes                         410      +410
__pyx_scope_struct__with_phil      344      +344
TFModuleWrapper                    344      +344
FontEntry                          335      +335
PointerType                        334      +334
PathMetadata                       332      +332
DistInfoDistribution               325      +325
MiniProduction                     310      +310
MovedModule                        284      +284
NamedType                          251      +251
slice                              228      +228
Enum                               216      +216
And                                213      +213
TagSet                             199      +199
ExtensionFileLoader                192      +192
Tag                                160      +160
OrderedDict                        155      +155
objgraph growth list end
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   207    315.8 MiB    315.8 MiB   @profile
   208                             def test_dataset(data_path,
   209                                              BATCH_SIZE,
   210                                              IS_EAST_IMAGE_TEST):
   211                                 """
   212                                 Reads the TFRecords and creates TF Datasets
   213                                 :param data_path:
   214                                 :return:
   215                                 """
   216    315.8 MiB      0.0 MiB       _num_cores = 4
   217                             
   218    315.8 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   219    315.8 MiB      0.0 MiB       path = path.replace("//", "/")
   220   1191.2 MiB    875.5 MiB       files = tf.data.Dataset.list_files(path)
   221                                 # TF dataset APIs
   222   1191.2 MiB      0.0 MiB       dataset = files.interleave(
   223   1191.2 MiB      0.0 MiB           tf.data.TFRecordDataset,
   224   1191.2 MiB      0.0 MiB           cycle_length=_num_cores,
   225   1194.4 MiB      3.1 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   226   1195.6 MiB      1.2 MiB       dataset = dataset.shuffle(BATCH_SIZE*10, 42)
   227                                 # Map the generator output as features as a dict and label
   228   1195.6 MiB      0.0 MiB       if IS_EAST_IMAGE_TEST:
   229   1198.5 MiB      3.0 MiB           dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   230                                 else:
   231                                     dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   232                             
   233   1198.5 MiB      0.0 MiB       dataset = dataset.batch(batch_size=BATCH_SIZE, drop_remainder=False)
   234   1198.5 MiB      0.0 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   235                             
   236   1722.9 MiB    273.5 MiB       for features, label in dataset:
   237   1718.8 MiB      1.0 MiB           try:
   238   1718.8 MiB      1.3 MiB               for key in features.keys():
   239   1718.8 MiB      0.8 MiB                   print(".", sep="")#print(f"{features[key].shape}", sep= " ")
   240                                     #print("\n")
   241                                     except:
   242                                         print(".", sep="") #hacky way


objgraph growth list start
weakref                         10807      +929
builtin_function_or_method       4788      +899
tuple                           32122      +836
dict                            34971      +255
list                            16252      +226
LineLocation                      204      +204
OriginInfo                        111      +111
Location                          111      +111
set                              2724       +42
function                        63367       +36
Tensor                             28       +28
TF_Output                          28       +28
Operation                          26       +26
_InputList                         26       +26
cell                            14502       +24
Dimension                          24       +22
TraceableStack                     14       +14
module                           3461       +13
TensorShape                        16       +13
ModuleSpec                       3463       +12
SourceFileLoader                 3218       +12
TextIOWrapper                      16       +12
IncrementalEncoder                 15       +12
FileIO                             16       +12
BufferedWriter                     15       +12
_TemporaryFileWrapper              12       +12
_TemporaryFileCloser               12       +12
_ConvertedEntityFactoryInfo        12       +12
OrderedDict                       165       +10
ConversionOptions                  11       +10
Condition                          36        +4
deque                              18        +4
_local                             15        +4
PhysicalDevice                      4        +4
LogicalDevice                       4        +4
ObjectIdentitySet                   4        +4
ScopedTFGraph                       4        +4
GroupLock                           4        +4
DeviceSpecV1                        4        +3
TensorSpec                          5        +3
_EagerDefinedFunction               3        +3
ScopedTFFunction                    3        +3
_EagerDefinedFunctionDeleter        3        +3
FuncGraph                           3        +3
ObjectIdentityWeakSet               3        +3
frozenset                        1544        +1
Random                              3        +1
_RandomNameSequence                 2        +1
Graph                               1        +1
_VariableScopeStore                 1        +1
objgraph growth list end
Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
   166    303.8 MiB    303.8 MiB   @profile
   167                             def main(args):
   168                             
   169    303.8 MiB      0.0 MiB       memory_used = []
   170    303.8 MiB      0.0 MiB       process = psutil.Process(os.getpid())
   171                             
   172                                 #TODO add into argparser
   173    303.8 MiB      0.0 MiB       IS_EAST_IMAGE_TEST = True
   174                             
   175    303.8 MiB      0.0 MiB       NUM_ARRAYS_PER_FILE = 10000
   176                             
   177                                 #TODO decode function needs this value as part of dataset map function,  hence for now harcoded value
   178                                 # if needed chnage manually at func `numpy_array_decode` in dummy_dataset.py also
   179    303.8 MiB      0.0 MiB       NUM_FEATURES = 250
   180                             
   181    303.8 MiB      0.0 MiB       NUM_IMAGES_PER_FILE = 8
   182                             
   183    303.8 MiB      0.0 MiB       BATCH_SIZE = 4
   184    303.8 MiB      0.0 MiB       TRAIN_DATA = os.getcwd() + "/data/train_data_img"
   185    303.8 MiB      0.0 MiB       VAL_DATA = os.getcwd() + "/data/val_data_img"
   186    303.8 MiB      0.0 MiB       MODEL_DIR = os.getcwd() + "/data/" + "east_net"
   187    303.8 MiB      0.0 MiB       EXPORT_DIR = MODEL_DIR + "/" + "export"
   188    303.8 MiB      0.0 MiB       NUM_EPOCHS = 3
   189    303.8 MiB      0.0 MiB       NUM_SAMPLES_PER_FILE = NUM_IMAGES_PER_FILE
   190                             
   191                             
   192    303.8 MiB      0.0 MiB       if args["dataset"] == "numpy":
   193                                     IS_EAST_IMAGE_TEST = False
   194                                     BATCH_SIZE = 128
   195                                     TRAIN_DATA = os.getcwd() + "/data/train_data"
   196                                     VAL_DATA = os.getcwd() + "/data/val_data"
   197                                     MODEL_DIR = os.getcwd() + "/" + "data/fwd_nnet"
   198                                     EXPORT_DIR = MODEL_DIR + "/" + "export"
   199                                     NUM_EPOCHS = 25
   200                                     NUM_SAMPLES_PER_FILE = NUM_ARRAYS_PER_FILE
   201    303.8 MiB      0.0 MiB       elif args["dataset"] == "east":
   202    303.8 MiB      0.0 MiB           pass
   203                                 else:
   204                                     print_error("Invalid dataset")
   205                             
   206    303.8 MiB      0.0 MiB       TOTAL_STEPS_PER_FILE = NUM_SAMPLES_PER_FILE / BATCH_SIZE
   207                             
   208    303.8 MiB      0.0 MiB       if args["delete"] == True:
   209    304.0 MiB      0.1 MiB           print_info("Deleting old data files")
   210    304.0 MiB      0.0 MiB           shutil.rmtree(TRAIN_DATA)
   211    304.0 MiB      0.0 MiB           shutil.rmtree(VAL_DATA)
   212                             
   213    304.0 MiB      0.0 MiB       gen_data(IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST,
   214    304.0 MiB      0.0 MiB                TRAIN_DATA=TRAIN_DATA,
   215    304.0 MiB      0.0 MiB                VAL_DATA=VAL_DATA,
   216    304.0 MiB      0.0 MiB                NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE,
   217    304.0 MiB      0.0 MiB                NUM_FEATURES=NUM_FEATURES,
   218    315.8 MiB     11.8 MiB                number_files=int(args["num_tfrecord_files"]))
   219                             
   220    315.8 MiB      0.0 MiB       if args["mode"] == "test_iterator":
   221    315.8 MiB      0.0 MiB           print('objgraph growth list start')
   222    315.8 MiB      0.0 MiB           objgraph.show_growth(limit=50)
   223    315.8 MiB      0.0 MiB           print('objgraph growth list end')
   224                             
   225                             
   226    315.8 MiB      0.0 MiB           test_dataset(data_path=TRAIN_DATA,
   227    315.8 MiB      0.0 MiB                        BATCH_SIZE=BATCH_SIZE,
   228   1722.9 MiB   1407.1 MiB                        IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST)
   229                                     # test_dataset(VAL_DATA)
   230   1722.9 MiB      0.0 MiB           print('objgraph growth list start')
   231   1724.7 MiB      1.9 MiB           objgraph.show_growth(limit=50)
   232   1724.7 MiB      0.0 MiB           print('objgraph growth list end')
   233                             
   234   1724.7 MiB      0.0 MiB           return
   235                             
   236                                 # print(dataset_to_iterator(data_path=TRAIN_DATA))
   237                             
   238                                 if IS_EAST_IMAGE_TEST:
   239                                     model = EASTTFModel(model_root_directory="store")
   240                                 else:
   241                                     model = NNet()
   242                             
   243                                 estimator = tf.estimator.Estimator(model_fn=model,
   244                                                                    config=_init_tf_config(TOTAL_STEPS_PER_FILE=TOTAL_STEPS_PER_FILE,
   245                                                                                           MODEL_DIR=MODEL_DIR), params=None)
   246                                 memory_usage_psutil()
   247                                 print('objgraph growth list start')
   248                                 objgraph.show_growth(limit=50)
   249                                 print('objgraph growth list end')
   250                             
   251                                 # print(objgraph.get_leaking_objects())
   252                             
   253                                 for epoch in tqdm(range(NUM_EPOCHS)):
   254                             
   255                                     print("\n\n\n\n\n\n")
   256                                     print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch")
   257                                     memory_usage_psutil()
   258                                     memory_used.append(process.memory_info()[0] / float(2 ** 20))
   259                                     print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Training")
   260                                     train(estimator=estimator,
   261                                           TRAIN_DATA=TRAIN_DATA,
   262                                           BATCH_SIZE=BATCH_SIZE,
   263                                           IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST)
   264                                     print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Evaluating")
   265                                     evaluate(estimator=estimator,
   266                                              VAL_DATA=VAL_DATA,
   267                                              BATCH_SIZE=BATCH_SIZE,
   268                                              IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST)
   269                                     print('objgraph growth list start')
   270                                     objgraph.show_growth(limit=50)
   271                                     print('objgraph growth list end')
   272                             
   273                             
   274                                 plt.plot(memory_used)
   275                                 plt.title('Evolution of memory')
   276                                 plt.xlabel('iteration')
   277                                 plt.ylabel('memory used (MB)')
   278                                 plt.savefig("memory_usage.png")
   279                                 plt.show()
   280                             
   281                                 print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch")
   282                                 export_model(estimator=estimator, model_export_path=EXPORT_DIR)
   283                             
   284                                 (objgraph.get_leaking_objects())


Top 100 lines
#1: python3.7/posixpath.py:365: 502.4 KiB
    path = sep*initial_slashes + path
#2: site-packages/memory_profiler.py:710: 247.5 KiB
    self._original_trace_function(frame, event, arg)
#3: python3.7/abc.py:143: 181.3 KiB
    return _abc_subclasscheck(cls, subclass)
#4: python3.7/linecache.py:137: 159.2 KiB
    lines = fp.readlines()
#5: python3.7/inspect.py:742: 144.0 KiB
    os.path.realpath(f)] = module.__name__
#6: python3.7/inspect.py:738: 144.0 KiB
    _filesbymodname[modname] = f
#7: python3.7/ast.py:326: 74.9 KiB
    new_node = self.visit(old_value)
#8: util/tf_stack.py:195: 72.4 KiB
    ret.append((filename, lineno, name, frame_globals, func_start_lineno))
#9: site-packages/memory_profiler.py:694: 60.5 KiB
    if frame.f_code in self.code_map:
#10: core/converter.py:346: 42.5 KiB
    return super(Base, self).visit(node)
#11: python3.7/ast.py:262: 39.0 KiB
    return visitor(node)
#12: <string>:1: 38.6 KiB
#13: static_analysis/liveness.py:161: 37.7 KiB
    node = super(Annotator, self).visit(node)
#14: site-packages/objgraph.py:309: 36.0 KiB
    peak_stats[name] = count
#15: static_analysis/reaching_definitions.py:307: 23.9 KiB
    node = super(TreeAnnotator, self).visit(node)
#16: python3.7/ast.py:260: 22.2 KiB
    method = 'visit_' + node.__class__.__name__
#17: util/tf_stack.py:182: 17.4 KiB
    lineno = f.f_lineno
#18: util/tf_stack.py:187: 16.5 KiB
    func_start_lineno = co.co_firstlineno
#19: python3.7/sre_parse.py:426: 13.2 KiB
    not nested and not items))
#20: pyct/transformer.py:371: 10.1 KiB
    replacement = self.visit(node)
#21: python3.7/contextlib.py:82: 9.2 KiB
    self.gen = func(*args, **kwds)
#22: pyct/origin_info.py:245: 8.6 KiB
    source_lines = source.split('\n')
#23: site-packages/objgraph.py:311: 8.5 KiB
    reverse=True)
#24: python3.7/sre_compile.py:783: 8.4 KiB
    groupindex, tuple(indexgroup)
#25: python3.7/ast.py:35: 8.0 KiB
    return compile(source, filename, mode, PyCF_ONLY_AST)
#26: python3.7/tempfile.py:550: 7.7 KiB
    newline=newline, encoding=encoding)
#27: astor/node_util.py:143: 7.6 KiB
    return visitor(node)
#28: python3.7/ast.py:266: 7.5 KiB
    for field, value in iter_fields(node):
#29: python3.7/ast.py:317: 7.4 KiB
    value = self.visit(value)
#30: psutil/_pslinux.py:1724: 7.0 KiB
    ctime = float(self._parse_stat_file()['create_time'])
#31: tensorflow/__init__.py:46: 7.0 KiB
    self.__dict__.update(module.__dict__)
#32: pyct/origin_info.py:138: 6.9 KiB
    source_map[line_loc] = origin_info
#33: site-packages/objgraph.py:315: 6.6 KiB
    return [(name, stats[name], delta) for name, delta in deltas]
#34: site-packages/objgraph.py:1109: 5.1 KiB
    return _get_obj_type(obj).__name__
#35: impl/conversion.py:621: 4.5 KiB
    ag_internal.__dict__.update(operators.__dict__)
#36: pyct/transformer.py:237: 4.3 KiB
    self.state = _State()
#37: pyct/qual_names.py:97: 4.1 KiB
    self.qn = (base,)
#38: framework/ops.py:1713: 4.1 KiB
    self._graph = g
#39: framework/func_graph.py:410: 4.0 KiB
    self._auto_cast_variable_read_dtype = old_auto_cast_var_read_dtype
#40: pyct/anno.py:123: 4.0 KiB
    node._fields += (field_name,)
#41: gast/astn.py:17: 3.8 KiB
    def generic_visit(self, node):
#42: python3.7/ast.py:312: 3.8 KiB
    for field, old_value in iter_fields(node):
#43: site-packages/memory_profiler.py:781: 3.6 KiB
    stream.write(unicode(tmp, 'UTF-8'))
#44: <frozen importlib._bootstrap_external>:59: 3.5 KiB
#45: astor/code_gen.py:531: 3.5 KiB
    self.write(node.id)
#46: util/object_identity.py:160: 3.3 KiB
    self._storage = set([self._wrap_key(obj) for obj in list(*args)])
#47: framework/ops.py:1786: 3.1 KiB
    for i, output_type in enumerate(output_types)
#48: python3.7/ast.py:172: 3.0 KiB
    def iter_fields(node):
#49: framework/ops.py:5483: 3.0 KiB
    yield g
#50: framework/ops.py:2838: 2.9 KiB
    self._thread_local = threading.local()
#51: framework/func_graph.py:195: 2.9 KiB
    self.control_outputs = []
#52: python/pywrap_tensorflow_internal.py:44: 2.6 KiB
    self.__dict__[name] = value
#53: python3.7/ast.py:258: 2.6 KiB
    def visit(self, node):
#54: python3.7/threading.py:348: 2.6 KiB
    waiters_to_notify = _deque(_islice(all_waiters, n))
#55: pyct/origin_info.py:181: 2.5 KiB
    return node.lineno + self._lineno_offset
#56: python3.7/tempfile.py:146: 2.5 KiB
    self._rng = _Random()
#57: gast/gast.py:13: 2.5 KiB
    self._fields = Fields
#58: python3.7/weakref.py:407: 2.3 KiB
    self.data[ref(key, self._remove)] = value
#59: <frozen importlib._bootstrap_external>:525: 2.3 KiB
#60: framework/ops.py:5268: 2.2 KiB
    def get_default(self):
#61: impl/api.py:541: 2.2 KiB
    result = converted_f(*effective_args)
#62: util/module_wrapper.py:93: 2.2 KiB
    self.__dict__.update(wrapped.__dict__)
#63: tqdm/_tqdm.py:516: 2.2 KiB
    cls.monitor = None
#64: estimator/__init__.py:40: 2.2 KiB
    from tensorflow_estimator.python.estimator.exporter import BestExporter
#65: python3.7/inspect.py:732: 2.1 KiB
    for modname, module in list(sys.modules.items()):
#66: framework/ops.py:384: 2.1 KiB
    self._op = op
#67: python3.7/sre_compile.py:209: 2.0 KiB
    _compile(code, av, flags)
#68: python3.7/sre_compile.py:148: 2.0 KiB
    _compile(code, av[2], flags)
#69: framework/ops.py:3429: 2.0 KiB
    op_def=op_def)
#70: pyct/compiler.py:103: 1.9 KiB
    atexit.register(lambda: os.remove(f.name))
#71: tracking/base.py:598: 1.9 KiB
    self._self_unconditional_deferred_dependencies = {}
#72: python3.7/threading.py:238: 1.8 KiB
    self._waiters = _deque()
#73: python3.7/weakref.py:288: 1.8 KiB
    def update(*args, **kwargs):
#74: operators/control_flow.py:1004: 1.8 KiB
    return body() if cond else orelse()
#75: tf_issue_32052/dummy_datasets.py:108: 1.8 KiB
    for i in tqdm(range(number_files)):
#76: impl/api.py:539: 1.7 KiB
    result = converted_f(*effective_args, **kwargs)
#77: ops/dataset_ops.py:153: 1.7 KiB
    self._graph_attr = ops.get_default_graph()
#78: eager/function.py:101: 1.6 KiB
    return tuple(self._hash_fix(i) for i in elem)
#79: eager/function.py:2038: 1.6 KiB
    capture_by_value=self._capture_by_value),
#80: ops/dataset_ops.py:152: 1.6 KiB
    name="_variant_tracker")
#81: framework/ops.py:1882: 1.6 KiB
    return c_api.TF_OperationName(self._c_op)
#82: gast/gast.py:8: 1.6 KiB
    def create_node(self, *args, **kwargs):
#83: python3.7/tempfile.py:479: 1.6 KiB
    @_functools.wraps(func)
#84: python3.7/threading.py:552: 1.6 KiB
    signaled = self._cond.wait(timeout)
#85: static_analysis/activity.py:461: 1.6 KiB
    node.test = self.visit(node.test)
#86: static_analysis/activity.py:436: 1.6 KiB
    node.args = self.visit(node.args)
#87: impl/api.py:330: 1.6 KiB
    return f(*args, **kwargs)
#88: python3.7/functools.py:54: 1.6 KiB
    value = getattr(wrapped, attr)
#89: astor/code_gen.py:218: 1.6 KiB
    self.write(*statements)
#90: util/nest.py:634: 1.5 KiB
    path=subpath):
#91: gast/astn.py:22: 1.5 KiB
    new_node = getattr(to, cls)()
#92: framework/c_api_util.py:186: 1.5 KiB
    ret = c_api.TF_Output()
#93: psutil/_pslinux.py:1514: 1.5 KiB
    return fun(self, *args, **kwargs)
#94: util/dispatch.py:180: 1.5 KiB
    return target(*args, **kwargs)
#95: ops/dataset_ops.py:2634: 1.5 KiB
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
#96: framework/ops.py:2170: 1.4 KiB
    self._inputs_val = Operation._InputList(retval)
#97: framework/ops.py:2872: 1.4 KiB
    self._building_function = False
#98: tqdm/_tqdm.py:984: 1.4 KiB
    return self.format_meter(**self.format_dict)
#99: framework/ops.py:2822: 1.3 KiB
    self._lock = threading.RLock()
#100: python/pywrap_tensorflow_internal.py:1458: 1.3 KiB
    this = _pywrap_tensorflow_internal.new_TF_Output()
640 other: 256.1 KiB
640 other: 0.3 MiB
Total allocated size: 2397.2 KiB
Total allocated size: 2.3 MiB
