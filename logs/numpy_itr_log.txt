WARNING: Logging before flag parsing goes to stderr.
E0903 10:16:26.651705 140479749183296 print_helper.py:68] [31m{'delete': True, 'mode': 'test_iterator', 'dataset': 'numpy', 'num_tfrecord_files': '6'}[0m
I0903 10:16:27.014518 140479749183296 print_helper.py:59] [92mDeleting old data files[0m
  0%|          | 0/6 [00:00<?, ?it/s] 17%|â–ˆâ–‹        | 1/6 [00:02<00:13,  2.72s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:05<00:10,  2.70s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:08<00:08,  2.71s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:10<00:05,  2.72s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:13<00:02,  2.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:16<00:00,  2.74s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.69s/it]2019-09-03 10:16:50.200451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-09-03 10:16:50.223321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:50.224040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-09-03 10:16:50.228204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 10:16:50.231587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-09-03 10:16:50.233796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-09-03 10:16:50.235526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-09-03 10:16:50.848912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-09-03 10:16:50.855657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-09-03 10:16:52.342163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-09-03 10:16:52.342292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.343020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.343663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-09-03 10:16:52.344207: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-03 10:16:52.371979: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-09-03 10:16:52.373657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562acec89410 executing computations on platform Host. Devices:
2019-09-03 10:16:52.373707: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-09-03 10:16:52.429393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.429859: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562acec4d3d0 executing computations on platform CUDA. Devices:
2019-09-03 10:16:52.429875: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1060 with Max-Q Design, Compute Capability 6.1
2019-09-03 10:16:52.430055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.430470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-09-03 10:16:52.430504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 10:16:52.430516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-09-03 10:16:52.430546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-09-03 10:16:52.430558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-09-03 10:16:52.430568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-09-03 10:16:52.430579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-09-03 10:16:52.430608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-09-03 10:16:52.430701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.431160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.431577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-09-03 10:16:52.431639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-09-03 10:16:52.432668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-03 10:16:52.432678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-09-03 10:16:52.432682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-09-03 10:16:52.432911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.433347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-09-03 10:16:52.433765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5166 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)

W0903 10:16:52.964758 140479749183296 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0903 10:17:09.661396 140479749183296 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object numpy_array_decode at 0x7fc368f50e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 126>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
2019-09-03 10:17:09.747598: W tensorflow/core/framework/model.cc:855] Failed to find a tunable parameter that would decrease the output time. This means that the autotuning optimization got stuck in a local maximum. The optimization attempt will be aborted.
2019-09-03 10:17:09.827768: W tensorflow/core/framework/model.cc:855] Failed to find a tunable parameter that would decrease the output time. This means that the autotuning optimization got stuck in a local maximum. The optimization attempt will be aborted.
2019-09-03 10:17:09.987949: W tensorflow/core/framework/model.cc:855] Failed to find a tunable parameter that would decrease the output time. This means that the autotuning optimization got stuck in a local maximum. The optimization attempt will be aborted.
2019-09-03 10:17:10.308134: W tensorflow/core/framework/model.cc:855] Failed to find a tunable parameter that would decrease the output time. This means that the autotuning optimization got stuck in a local maximum. The optimization attempt will be aborted.
Writing to /opt/tf_issue_32052/data/train_data/0.tfrecords
Writing to /opt/tf_issue_32052/data/train_data/1.tfrecords
Writing to /opt/tf_issue_32052/data/train_data/2.tfrecords
Writing to /opt/tf_issue_32052/data/train_data/3.tfrecords
Writing to /opt/tf_issue_32052/data/train_data/4.tfrecords
Writing to /opt/tf_issue_32052/data/train_data/5.tfrecords
Writing to /opt/tf_issue_32052/data/val_data/0.tfrecords
Writing to /opt/tf_issue_32052/data/val_data/1.tfrecords
Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
   142    303.8 MiB    303.8 MiB   @profile
   143                             def gen_data(number_files,
   144                                          IS_EAST_IMAGE_TEST,
   145                                          TRAIN_DATA,
   146                                          VAL_DATA,
   147                                          NUM_SAMPLES_PER_FILE,
   148                                          NUM_FEATURES=None):
   149    303.8 MiB      0.0 MiB       if IS_EAST_IMAGE_TEST:
   150                                     generate_image_tf_records(number_files=number_files,
   151                                                               out_dir=TRAIN_DATA,
   152                                                               NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)
   153                                     generate_image_tf_records(number_files=2, #TODO Fixed?
   154                                                               out_dir=VAL_DATA,
   155                                                               NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)
   156                                 else:
   157    303.8 MiB      0.0 MiB           generate_numpy_tf_records(number_files=number_files,
   158    303.8 MiB      0.0 MiB                                     out_dir=TRAIN_DATA,
   159    303.8 MiB      0.0 MiB                                     NUM_FEATURES=NUM_FEATURES,
   160    362.7 MiB     58.9 MiB                                     NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)
   161    362.7 MiB      0.0 MiB           generate_numpy_tf_records(number_files=2, #TODO fixed?
   162    362.7 MiB      0.0 MiB                                     out_dir=VAL_DATA,
   163    362.7 MiB      0.0 MiB                                     NUM_FEATURES=NUM_FEATURES,
   164    381.5 MiB     18.8 MiB                                     NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE)


objgraph growth list start
function                         63331    +63331
dict                             34719    +34719
tuple                            31289    +31289
list                             16026    +16026
cell                             14478    +14478
weakref                           9882     +9882
type                              6925     +6925
getset_descriptor                 6511     +6511
property                          4967     +4967
builtin_function_or_method        3890     +3890
ModuleSpec                        3451     +3451
module                            3448     +3448
wrapper_descriptor                3350     +3350
SourceFileLoader                  3206     +3206
method_descriptor                 3152     +3152
set                               2682     +2682
TFDecorator                       1729     +1729
frozenset                         1543     +1543
ArgSpec                           1224     +1224
_OpInfo                           1224     +1224
method                            1174     +1174
classmethod                       1168     +1168
staticmethod                      1099     +1099
member_descriptor                  944      +944
TagMap                             803      +803
cython_function_or_method          608      +608
fused_cython_function              571      +571
ABCMeta                            562      +562
GeneratedProtocolMessageType       505      +505
MovedAttribute                     496      +496
FileFinder                         463      +463
vectorize                          454      +454
Parameter                          452      +452
NamedTypes                         410      +410
__pyx_scope_struct__with_phil      344      +344
TFModuleWrapper                    344      +344
FontEntry                          335      +335
PointerType                        334      +334
PathMetadata                       332      +332
DistInfoDistribution               325      +325
MiniProduction                     310      +310
MovedModule                        284      +284
NamedType                          251      +251
slice                              228      +228
Enum                               216      +216
And                                213      +213
TagSet                             199      +199
ExtensionFileLoader                192      +192
Tag                                160      +160
OrderedDict                        155      +155
objgraph growth list end
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   207    324.5 MiB    324.5 MiB   
   208                             
   209                             @profile
   210                             def test_dataset(data_path,
   211                                              BATCH_SIZE,
   212                                              IS_EAST_IMAGE_TEST):
   213                                 """
   214                                 Reads the TFRecords and creates TF Datasets
   215                                 :param data_path:
   216    324.5 MiB      0.0 MiB       :return:
   217                                 """
   218    324.5 MiB      0.0 MiB       _num_cores = 4
   219    324.5 MiB      0.0 MiB   
   220   1183.4 MiB    858.9 MiB       path = os.path.join(data_path, "*.tfrecords")
   221                                 path = path.replace("//", "/")
   222   1183.4 MiB      0.0 MiB       files = tf.data.Dataset.list_files(path)
   223   1183.4 MiB      0.0 MiB       # TF dataset APIs
   224   1183.4 MiB      0.0 MiB       dataset = files.interleave(
   225   1187.3 MiB      3.9 MiB           tf.data.TFRecordDataset,
   226   1187.3 MiB      0.0 MiB           cycle_length=_num_cores,
   227                                     num_parallel_calls=tf.data.experimental.AUTOTUNE)
   228   1187.3 MiB      0.0 MiB       dataset = dataset.shuffle(BATCH_SIZE*10, 42)
   229                                 # Map the generator output as features as a dict and label
   230                                 if IS_EAST_IMAGE_TEST:
   231   1192.3 MiB      5.0 MiB           dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   232                                 else:
   233   1192.3 MiB      0.0 MiB           dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   234   1192.3 MiB      0.0 MiB   
   235                                 dataset = dataset.batch(batch_size=BATCH_SIZE, drop_remainder=False)
   236   1201.5 MiB      6.6 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   237   1199.1 MiB      0.0 MiB   
   238   1199.1 MiB      0.0 MiB       for features, label in dataset:
   239   1199.1 MiB      0.0 MiB           try:
   240                                         for key in features.keys():
   241                                             print(".", sep="")#print(f"{features[key].shape}", sep= " ")
   242                                     #print("\n")


objgraph growth list start
weakref                         10811      +929
builtin_function_or_method       4789      +899
tuple                           31989      +700
dict                            34954      +235
LineLocation                      203      +203
list                            16223      +197
OriginInfo                        110      +110
Location                          110      +110
set                              2724       +42
function                        63367       +36
cell                            14502       +24
Tensor                             22       +22
TF_Output                          22       +22
Operation                          21       +21
_InputList                         21       +21
TraceableStack                     14       +14
module                           3461       +13
ModuleSpec                       3463       +12
SourceFileLoader                 3218       +12
TextIOWrapper                      16       +12
IncrementalEncoder                 15       +12
FileIO                             16       +12
BufferedWriter                     15       +12
_TemporaryFileWrapper              12       +12
_TemporaryFileCloser               12       +12
_ConvertedEntityFactoryInfo        12       +12
OrderedDict                       165       +10
ConversionOptions                  11       +10
TensorShape                        13       +10
Dimension                           9        +7
Condition                          36        +4
deque                              18        +4
_local                             15        +4
PhysicalDevice                      4        +4
LogicalDevice                       4        +4
ObjectIdentitySet                   4        +4
ScopedTFGraph                       4        +4
GroupLock                           4        +4
DeviceSpecV1                        4        +3
TensorSpec                          5        +3
_EagerDefinedFunction               3        +3
ScopedTFFunction                    3        +3
_EagerDefinedFunctionDeleter        3        +3
FuncGraph                           3        +3
ObjectIdentityWeakSet               3        +3
frozenset                        1544        +1
Random                              3        +1
_RandomNameSequence                 2        +1
Graph                               1        +1
_VariableScopeStore                 1        +1
objgraph growth list end
Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
   166    303.6 MiB    303.6 MiB   @profile
   167                             def main(args):
   168                             
   169    303.6 MiB      0.0 MiB       memory_used = []
   170    303.6 MiB      0.0 MiB       process = psutil.Process(os.getpid())
   171                             
   172                                 #TODO add into argparser
   173    303.6 MiB      0.0 MiB       IS_EAST_IMAGE_TEST = True
   174                             
   175    303.6 MiB      0.0 MiB       NUM_ARRAYS_PER_FILE = 10000
   176                             
   177                                 #TODO decode function needs this value as part of dataset map function,  hence for now harcoded value
   178                                 # if needed chnage manually at func `numpy_array_decode` in dummy_dataset.py also
   179    303.6 MiB      0.0 MiB       NUM_FEATURES = 250
   180                             
   181    303.6 MiB      0.0 MiB       NUM_IMAGES_PER_FILE = 8
   182                             
   183    303.6 MiB      0.0 MiB       BATCH_SIZE = 4
   184    303.6 MiB      0.0 MiB       TRAIN_DATA = os.getcwd() + "/data/train_data_img"
   185    303.6 MiB      0.0 MiB       VAL_DATA = os.getcwd() + "/data/val_data_img"
   186    303.6 MiB      0.0 MiB       MODEL_DIR = os.getcwd() + "/data/" + "east_net"
   187    303.6 MiB      0.0 MiB       EXPORT_DIR = MODEL_DIR + "/" + "export"
   188    303.6 MiB      0.0 MiB       NUM_EPOCHS = 3
   189    303.6 MiB      0.0 MiB       NUM_SAMPLES_PER_FILE = NUM_IMAGES_PER_FILE
   190                             
   191                             
   192    303.6 MiB      0.0 MiB       if args["dataset"] == "numpy":
   193    303.6 MiB      0.0 MiB           IS_EAST_IMAGE_TEST = False
   194    303.6 MiB      0.0 MiB           BATCH_SIZE = 128
   195    303.6 MiB      0.0 MiB           TRAIN_DATA = os.getcwd() + "/data/train_data"
   196    303.6 MiB      0.0 MiB           VAL_DATA = os.getcwd() + "/data/val_data"
   197    303.6 MiB      0.0 MiB           MODEL_DIR = os.getcwd() + "/" + "data/fwd_nnet"
   198    303.6 MiB      0.0 MiB           EXPORT_DIR = MODEL_DIR + "/" + "export"
   199    303.6 MiB      0.0 MiB           NUM_EPOCHS = 10
   200    303.6 MiB      0.0 MiB           NUM_SAMPLES_PER_FILE = NUM_ARRAYS_PER_FILE
   201                                 elif args["dataset"] == "east":
   202                                     pass
   203                                 else:
   204                                     print_error("Invalid dataset")
   205                             
   206    303.6 MiB      0.0 MiB       TOTAL_STEPS_PER_FILE = NUM_SAMPLES_PER_FILE / BATCH_SIZE
   207                             
   208    303.6 MiB      0.0 MiB       if args["delete"] == True:
   209    303.6 MiB      0.0 MiB           print_info("Deleting old data files")
   210    303.8 MiB      0.1 MiB           shutil.rmtree(TRAIN_DATA)
   211    303.8 MiB      0.0 MiB           shutil.rmtree(VAL_DATA)
   212                             
   213    303.8 MiB      0.0 MiB       gen_data(IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST,
   214    303.8 MiB      0.0 MiB                TRAIN_DATA=TRAIN_DATA,
   215    303.8 MiB      0.0 MiB                VAL_DATA=VAL_DATA,
   216    303.8 MiB      0.0 MiB                NUM_SAMPLES_PER_FILE=NUM_SAMPLES_PER_FILE,
   217    303.8 MiB      0.0 MiB                NUM_FEATURES=NUM_FEATURES,
   218    381.5 MiB     77.7 MiB                number_files=int(args["num_tfrecord_files"]))
   219                             
   220    381.5 MiB      0.0 MiB       if args["mode"] == "test_iterator":
   221    381.5 MiB      0.0 MiB           print('objgraph growth list start')
   222    324.5 MiB      0.0 MiB           objgraph.show_growth(limit=50)
   223    324.5 MiB      0.0 MiB           print('objgraph growth list end')
   224                             
   225                             
   226    324.5 MiB      0.0 MiB           test_dataset(data_path=TRAIN_DATA,
   227    324.5 MiB      0.0 MiB                        BATCH_SIZE=BATCH_SIZE,
   228   1201.5 MiB    877.0 MiB                        IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST)
   229                                     # test_dataset(VAL_DATA)
   230   1201.5 MiB      0.0 MiB           print('objgraph growth list start')
   231   1203.1 MiB      1.7 MiB           objgraph.show_growth(limit=50)
   232   1203.1 MiB      0.0 MiB           print('objgraph growth list end')
   233                             
   234   1203.1 MiB      0.0 MiB           return
   235                             
   236                                 # print(dataset_to_iterator(data_path=TRAIN_DATA))
   237                             
   238                                 if IS_EAST_IMAGE_TEST:
   239                                     model = EASTTFModel(model_root_directory="store")
   240                                 else:
   241                                     model = NNet()
   242                             
   243                                 estimator = tf.estimator.Estimator(model_fn=model,
   244                                                                    config=_init_tf_config(TOTAL_STEPS_PER_FILE=TOTAL_STEPS_PER_FILE,
   245                                                                                           MODEL_DIR=MODEL_DIR), params=None)
   246                                 memory_usage_psutil()
   247                                 print('objgraph growth list start')
   248                                 objgraph.show_growth(limit=50)
   249                                 print('objgraph growth list end')
   250                             
   251                                 # print(objgraph.get_leaking_objects())
   252                             
   253                                 for epoch in tqdm(range(NUM_EPOCHS)):
   254                             
   255                                     print("\n\n\n\n\n\n")
   256                                     print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch")
   257                                     memory_usage_psutil()
   258                                     memory_used.append(process.memory_info()[0] / float(2 ** 20))
   259                                     print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Training")
   260                                     train(estimator=estimator,
   261                                           TRAIN_DATA=TRAIN_DATA,
   262                                           BATCH_SIZE=BATCH_SIZE,
   263                                           IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST)
   264                                     print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Evaluating")
   265                                     evaluate(estimator=estimator,
   266                                              VAL_DATA=VAL_DATA,
   267                                              BATCH_SIZE=BATCH_SIZE,
   268                                              IS_EAST_IMAGE_TEST=IS_EAST_IMAGE_TEST)
   269                                     print('objgraph growth list start')
   270                                     objgraph.show_growth(limit=50)
   271                                     print('objgraph growth list end')
   272                             
   273                             
   274                                 plt.plot(memory_used)
   275                                 plt.title('Evolution of memory')
   276                                 plt.xlabel('iteration')
   277                                 plt.ylabel('memory used (MB)')
   278                                 plt.savefig("memory_usage.png")
   279                                 plt.show()
   280                             
   281                                 print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch")
   282                                 export_model(estimator=estimator, model_export_path=EXPORT_DIR)
   283                             
   284                                 (objgraph.get_leaking_objects())


Top 100 lines
#1: python3.7/posixpath.py:365: 502.4 KiB
    path = sep*initial_slashes + path
#2: site-packages/memory_profiler.py:710: 253.5 KiB
    self._original_trace_function(frame, event, arg)
#3: python3.7/abc.py:143: 182.0 KiB
    return _abc_subclasscheck(cls, subclass)
#4: python3.7/linecache.py:137: 159.3 KiB
    lines = fp.readlines()
#5: python3.7/inspect.py:742: 144.0 KiB
    os.path.realpath(f)] = module.__name__
#6: python3.7/inspect.py:738: 144.0 KiB
    _filesbymodname[modname] = f
#7: python3.7/ast.py:326: 76.0 KiB
    new_node = self.visit(old_value)
#8: site-packages/memory_profiler.py:694: 60.5 KiB
    if frame.f_code in self.code_map:
#9: util/tf_stack.py:195: 59.5 KiB
    ret.append((filename, lineno, name, frame_globals, func_start_lineno))
#10: core/converter.py:346: 45.7 KiB
    return super(Base, self).visit(node)
#11: python3.7/ast.py:262: 38.8 KiB
    return visitor(node)
#12: <string>:1: 38.7 KiB
#13: static_analysis/liveness.py:161: 36.1 KiB
    node = super(Annotator, self).visit(node)
#14: site-packages/objgraph.py:309: 36.0 KiB
    peak_stats[name] = count
#15: static_analysis/reaching_definitions.py:307: 22.3 KiB
    node = super(TreeAnnotator, self).visit(node)
#16: python3.7/ast.py:260: 22.0 KiB
    method = 'visit_' + node.__class__.__name__
#17: util/tf_stack.py:182: 14.5 KiB
    lineno = f.f_lineno
#18: util/tf_stack.py:187: 13.7 KiB
    func_start_lineno = co.co_firstlineno
#19: python3.7/sre_parse.py:426: 13.2 KiB
    not nested and not items))
#20: pyct/transformer.py:371: 9.6 KiB
    replacement = self.visit(node)
#21: python3.7/contextlib.py:82: 8.7 KiB
    self.gen = func(*args, **kwds)
#22: site-packages/objgraph.py:311: 8.7 KiB
    reverse=True)
#23: pyct/origin_info.py:245: 8.5 KiB
    source_lines = source.split('\n')
#24: python3.7/sre_compile.py:783: 8.4 KiB
    groupindex, tuple(indexgroup)
#25: astor/node_util.py:143: 8.1 KiB
    return visitor(node)
#26: python3.7/ast.py:317: 8.0 KiB
    value = self.visit(value)
#27: python3.7/tempfile.py:550: 7.7 KiB
    newline=newline, encoding=encoding)
#28: python3.7/ast.py:266: 7.5 KiB
    for field, value in iter_fields(node):
#29: python3.7/ast.py:35: 7.3 KiB
    return compile(source, filename, mode, PyCF_ONLY_AST)
#30: tensorflow/__init__.py:46: 7.0 KiB
    self.__dict__.update(module.__dict__)
#31: pyct/origin_info.py:138: 6.9 KiB
    source_map[line_loc] = origin_info
#32: psutil/_pslinux.py:1724: 6.5 KiB
    ctime = float(self._parse_stat_file()['create_time'])
#33: site-packages/objgraph.py:315: 6.5 KiB
    return [(name, stats[name], delta) for name, delta in deltas]
#34: site-packages/objgraph.py:1109: 5.2 KiB
    return _get_obj_type(obj).__name__
#35: site-packages/memory_profiler.py:781: 4.9 KiB
    stream.write(unicode(tmp, 'UTF-8'))
#36: pyct/qual_names.py:97: 4.6 KiB
    self.qn = (base,)
#37: impl/conversion.py:621: 4.5 KiB
    ag_internal.__dict__.update(operators.__dict__)
#38: pyct/transformer.py:237: 4.3 KiB
    self.state = _State()
#39: framework/func_graph.py:410: 4.0 KiB
    self._auto_cast_variable_read_dtype = old_auto_cast_var_read_dtype
#40: python3.7/ast.py:312: 3.8 KiB
    for field, old_value in iter_fields(node):
#41: pyct/anno.py:123: 3.7 KiB
    node._fields += (field_name,)
#42: <frozen importlib._bootstrap_external>:59: 3.5 KiB
#43: astor/code_gen.py:531: 3.5 KiB
    self.write(node.id)
#44: gast/astn.py:17: 3.4 KiB
    def generic_visit(self, node):
#45: core/_internal.py:282: 3.4 KiB
    c_arr = (ctypes.c_char * 0).from_buffer(simple_arr)
#46: util/object_identity.py:160: 3.3 KiB
    self._storage = set([self._wrap_key(obj) for obj in list(*args)])
#47: framework/ops.py:1713: 3.3 KiB
    self._graph = g
#48: framework/ops.py:5483: 3.0 KiB
    yield g
#49: framework/ops.py:2838: 2.9 KiB
    self._thread_local = threading.local()
#50: framework/func_graph.py:195: 2.9 KiB
    self.control_outputs = []
#51: framework/ops.py:1786: 2.6 KiB
    for i, output_type in enumerate(output_types)
#52: python3.7/threading.py:348: 2.6 KiB
    waiters_to_notify = _deque(_islice(all_waiters, n))
#53: python3.7/inspect.py:732: 2.6 KiB
    for modname, module in list(sys.modules.items()):
#54: pyct/origin_info.py:181: 2.5 KiB
    return node.lineno + self._lineno_offset
#55: python3.7/tempfile.py:146: 2.5 KiB
    self._rng = _Random()
#56: python3.7/weakref.py:407: 2.3 KiB
    self.data[ref(key, self._remove)] = value
#57: python3.7/ast.py:258: 2.3 KiB
    def visit(self, node):
#58: <frozen importlib._bootstrap_external>:525: 2.3 KiB
#59: impl/api.py:541: 2.2 KiB
    result = converted_f(*effective_args)
#60: python3.7/ast.py:172: 2.2 KiB
    def iter_fields(node):
#61: python/pywrap_tensorflow_internal.py:44: 2.2 KiB
    self.__dict__[name] = value
#62: util/module_wrapper.py:93: 2.2 KiB
    self.__dict__.update(wrapped.__dict__)
#63: tqdm/_tqdm.py:516: 2.2 KiB
    cls.monitor = None
#64: estimator/__init__.py:40: 2.2 KiB
    from tensorflow_estimator.python.estimator.exporter import BestExporter
#65: eager/function.py:101: 2.1 KiB
    return tuple(self._hash_fix(i) for i in elem)
#66: framework/ops.py:5268: 2.1 KiB
    def get_default(self):
#67: gast/gast.py:13: 2.0 KiB
    self._fields = Fields
#68: python3.7/sre_compile.py:209: 2.0 KiB
    _compile(code, av, flags)
#69: python3.7/sre_compile.py:148: 2.0 KiB
    _compile(code, av[2], flags)
#70: astor/code_gen.py:218: 1.9 KiB
    self.write(*statements)
#71: pyct/compiler.py:103: 1.9 KiB
    atexit.register(lambda: os.remove(f.name))
#72: tracking/base.py:598: 1.9 KiB
    self._self_unconditional_deferred_dependencies = {}
#73: python3.7/weakref.py:288: 1.9 KiB
    def update(*args, **kwargs):
#74: python3.7/threading.py:238: 1.8 KiB
    self._waiters = _deque()
#75: operators/control_flow.py:1004: 1.8 KiB
    return body() if cond else orelse()
#76: tf_issue_32052/dummy_datasets.py:77: 1.8 KiB
    for i in tqdm(range(number_files)):
#77: impl/api.py:539: 1.7 KiB
    result = converted_f(*effective_args, **kwargs)
#78: framework/ops.py:3429: 1.7 KiB
    op_def=op_def)
#79: ops/dataset_ops.py:153: 1.7 KiB
    self._graph_attr = ops.get_default_graph()
#80: framework/ops.py:384: 1.6 KiB
    self._op = op
#81: eager/function.py:2038: 1.6 KiB
    capture_by_value=self._capture_by_value),
#82: gast/astn.py:22: 1.6 KiB
    new_node = getattr(to, cls)()
#83: ops/dataset_ops.py:152: 1.6 KiB
    name="_variant_tracker")
#84: python3.7/tempfile.py:479: 1.6 KiB
    @_functools.wraps(func)
#85: python3.7/threading.py:552: 1.6 KiB
    signaled = self._cond.wait(timeout)
#86: impl/api.py:330: 1.6 KiB
    return f(*args, **kwargs)
#87: util/nest.py:634: 1.5 KiB
    path=subpath):
#88: psutil/_pslinux.py:1514: 1.5 KiB
    return fun(self, *args, **kwargs)
#89: ops/dataset_ops.py:2634: 1.5 KiB
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
#90: python3.7/functools.py:54: 1.5 KiB
    value = getattr(wrapped, attr)
#91: core/_internal.py:285: 1.5 KiB
    return ctypes.cast(ctypes.pointer(c_arr), ctypes.c_void_p)
#92: python3.7/sre_parse.py:112: 1.5 KiB
    self.pattern = pattern
#93: util/dispatch.py:180: 1.5 KiB
    return target(*args, **kwargs)
#94: framework/ops.py:2872: 1.4 KiB
    self._building_function = False
#95: gast/gast.py:8: 1.4 KiB
    def create_node(self, *args, **kwargs):
#96: tqdm/_tqdm.py:984: 1.4 KiB
    return self.format_meter(**self.format_dict)
#97: framework/ops.py:2822: 1.3 KiB
    self._lock = threading.RLock()
#98: framework/ops.py:1882: 1.3 KiB
    return c_api.TF_OperationName(self._c_op)
#99: framework/ops.py:2867: 1.3 KiB
    self._functions = collections.OrderedDict()
#100: python3.7/_collections_abc.py:392: 1.3 KiB
    @classmethod
653 other: 252.3 KiB
653 other: 0.2 MiB
Total allocated size: 2380.3 KiB
Total allocated size: 2.3 MiB
