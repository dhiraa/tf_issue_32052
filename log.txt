  0%|          | 0/5 [00:00<?, ?it/s]Writing to /opt/tf_issue_32052/data/train_data_img/0.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    308.2 MiB    308.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    315.2 MiB      6.9 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    315.2 MiB    315.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    315.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    315.2 MiB    315.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    315.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    308.2 MiB    308.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    315.2 MiB      6.9 MiB           "images": _mat_feature(image_mat),
    57    315.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    315.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    320.2 MiB    320.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB     11.1 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    320.2 MiB    320.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    331.3 MiB     11.1 MiB           "images": _mat_feature(image_mat),
    57    331.3 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    331.3 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.5 MiB    331.5 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.6 MiB      1.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.6 MiB    332.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.6 MiB    332.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.8 MiB      0.3 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    331.5 MiB    331.5 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.6 MiB      1.0 MiB           "images": _mat_feature(image_mat),
    57    332.6 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.8 MiB      0.3 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.8 MiB    332.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.8 MiB    332.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.8 MiB    332.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    332.8 MiB    332.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.8 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    332.8 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.8 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.8 MiB    332.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.1 MiB      0.3 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

 20%|██        | 1/5 [00:02<00:08,  2.14s/it]Line #    Mem usage    Increment   Line Contents
================================================
    22    333.1 MiB    333.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.1 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    333.1 MiB    333.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.1 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    332.8 MiB    332.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    333.1 MiB      0.3 MiB           "images": _mat_feature(image_mat),
    57    333.1 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    333.1 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    333.6 MiB    333.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    333.6 MiB    333.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    333.6 MiB    333.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    333.6 MiB    333.6 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    333.6 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    333.6 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    333.6 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    322.2 MiB    322.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.0 MiB      8.8 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.0 MiB    331.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.0 MiB    331.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    322.2 MiB    322.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    331.0 MiB      8.8 MiB           "images": _mat_feature(image_mat),
    57    331.0 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    331.0 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.9 MiB    335.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Writing to /opt/tf_issue_32052/data/train_data_img/1.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.9 MiB    335.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.9 MiB    335.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.9 MiB    335.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    326.2 MiB    326.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.4 MiB      5.2 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.4 MiB    331.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.4 MiB    331.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    326.2 MiB    326.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    331.4 MiB      5.2 MiB           "images": _mat_feature(image_mat),
    57    331.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    331.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.4 MiB    331.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.0 MiB      2.6 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.0 MiB    334.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.0 MiB    334.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    331.4 MiB    331.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.0 MiB      2.6 MiB           "images": _mat_feature(image_mat),
    57    334.0 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.0 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    334.2 MiB    334.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
 40%|████      | 2/5 [00:04<00:06,  2.07s/it]    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.2 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    334.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    334.2 MiB    334.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.2 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    334.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    334.2 MiB    334.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.2 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    334.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.2 MiB    334.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    334.2 MiB    334.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.2 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    334.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Writing to /opt/tf_issue_32052/data/train_data_img/2.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.9 MiB    337.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.9 MiB    337.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.4 MiB    338.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.4 MiB    338.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.4 MiB    338.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    338.4 MiB    338.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    338.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    338.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    338.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.4 MiB    338.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.4 MiB    338.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.4 MiB    338.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    338.4 MiB    338.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    338.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    338.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    338.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    326.6 MiB    326.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      8.8 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    326.6 MiB    326.6 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.4 MiB      8.8 MiB           "images": _mat_feature(image_mat),
    57    335.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))
 60%|██████    | 3/5 [00:05<00:04,  2.01s/it]

Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.4 MiB    335.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.4 MiB    335.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.4 MiB    335.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Writing to /opt/tf_issue_32052/data/train_data_img/3.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    335.4 MiB    335.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    335.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    335.4 MiB    335.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    335.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    335.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    335.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.0 MiB    340.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.0 MiB    340.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.0 MiB    340.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.0 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    340.0 MiB    340.0 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    340.0 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    340.0 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    340.0 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    323.6 MiB    323.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.4 MiB      8.8 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.4 MiB    332.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.4 MiB    332.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    323.6 MiB    323.6 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.4 MiB      8.8 MiB           "images": _mat_feature(image_mat),
    57    332.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.3 MiB    337.3 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.3 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.3 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.3 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.3 MiB    337.3 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.3 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.3 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.3 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.3 MiB    337.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.3 MiB    337.3 MiB   @profile
 80%|████████  | 4/5 [00:07<00:01,  1.97s/it]    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.3 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.3 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.3 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    324.2 MiB    324.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      8.8 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    324.2 MiB    324.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.9 MiB      8.8 MiB           "images": _mat_feature(image_mat),
    57    332.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    332.9 MiB    332.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    332.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Writing to /opt/tf_issue_32052/data/train_data_img/4.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    332.9 MiB    332.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    332.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    332.9 MiB    332.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    332.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    332.9 MiB    332.9 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    332.9 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    332.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    332.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.8 MiB    337.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.8 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.8 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.8 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.8 MiB    337.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.8 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.8 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.8 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.8 MiB    337.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.8 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.8 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.8 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.8 MiB    337.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.8 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.8 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.8 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))
100%|██████████| 5/5 [00:09<00:00,  1.94s/it]
  0%|          | 0/2 [00:00<?, ?it/s]

Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.8 MiB    337.8 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.8 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.8 MiB    337.8 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.8 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.8 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.8 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.6 MiB    338.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.6 MiB    338.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    338.6 MiB    338.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    338.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    338.6 MiB    338.6 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    338.6 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    338.6 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    338.6 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    95    301.1 MiB    301.1 MiB   @profile
    96                             def generate_image_tf_records(number_files, out_dir):
    97                             
    98    301.1 MiB      0.0 MiB       if not os.path.exists(out_dir):
    99    301.1 MiB      0.0 MiB           os.makedirs(out_dir)
   100                             
   101    338.8 MiB      0.0 MiB       for i in tqdm(range(number_files)):
   102    335.9 MiB      0.0 MiB           file_path_name = os.path.join(out_dir, str(i) + ".tfrecords")
   103    335.9 MiB      0.0 MiB           print(f"Writing to {file_path_name}")
   104    335.9 MiB      0.0 MiB           if os.path.exists(file_path_name):
   105                                         print(f"Found : {file_path_name}")
   106                                         continue
   107    335.9 MiB      0.0 MiB           with tf.io.TFRecordWriter(file_path_name) as writer:
   108    340.0 MiB      0.0 MiB               for i in range(NUM_SAMPLES_PER_FILE):
   109    340.0 MiB      6.3 MiB                   image_mat = np.random.rand(512, 512, 3)
   110    340.0 MiB      0.0 MiB                   score_map_mat = np.random.rand(128, 128, 1)
   111    340.0 MiB      0.5 MiB                   geo_map_mat = np.random.rand(128, 128, 5)
   112    340.0 MiB      0.0 MiB                   features = tf.train.Features(
   113    340.0 MiB     12.1 MiB                       feature=_get_east_features(image_mat, score_map_mat, geo_map_mat))
   114    340.0 MiB      0.0 MiB                   example = tf.train.Example(features=features)
   115    340.0 MiB      0.3 MiB                   writer.write(example.SerializeToString())


Writing to /opt/tf_issue_32052/data/val_data_img/0.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    321.0 MiB    321.0 MiB   @profile
    23                             def _mat_feature(mat):
    24    323.1 MiB      2.1 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    323.1 MiB    323.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    323.1 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    323.1 MiB    323.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    323.1 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    321.0 MiB    321.0 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    323.1 MiB      2.1 MiB           "images": _mat_feature(image_mat),
    57    323.1 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    323.1 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    328.1 MiB    328.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.1 MiB      3.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.1 MiB    331.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.1 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.1 MiB    331.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.1 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    328.1 MiB    328.1 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    331.1 MiB      3.0 MiB           "images": _mat_feature(image_mat),
    57    331.1 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    331.1 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.1 MiB    331.1 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.9 MiB      2.8 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    333.9 MiB    333.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    333.9 MiB    333.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    333.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    331.1 MiB    331.1 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    333.9 MiB      2.8 MiB           "images": _mat_feature(image_mat),
    57    333.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    333.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    326.6 MiB    326.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    329.7 MiB      3.1 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    329.7 MiB    329.7 MiB   @profile
    23                             def _mat_feature(mat):
    24    329.7 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    329.7 MiB    329.7 MiB   @profile
    23                             def _mat_feature(mat):
    24    329.7 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    326.6 MiB    326.6 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    329.7 MiB      3.1 MiB           "images": _mat_feature(image_mat),
    57    329.7 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    329.7 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    336.2 MiB    336.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    336.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    336.2 MiB    336.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    336.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    336.2 MiB    336.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    336.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    336.2 MiB    336.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    336.2 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    336.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    336.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    336.9 MiB    336.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      1.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.9 MiB    337.9 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.9 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    336.7 MiB    336.7 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
 50%|█████     | 1/2 [00:01<00:01,  1.91s/it]    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.9 MiB      1.2 MiB           "images": _mat_feature(image_mat),
    57    337.9 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.9 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    340.4 MiB    340.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    340.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    340.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    340.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    340.4 MiB    340.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    340.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    340.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    340.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Writing to /opt/tf_issue_32052/data/val_data_img/1.tfrecords
Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.4 MiB    340.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    340.4 MiB    340.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    340.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    340.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    340.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.6 MiB    340.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.6 MiB    340.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    340.6 MiB    340.6 MiB   @profile
    23                             def _mat_feature(mat):
    24    340.6 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    340.4 MiB    340.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    340.6 MiB      0.1 MiB           "images": _mat_feature(image_mat),
    57    340.6 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    340.6 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    326.7 MiB    326.7 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      4.6 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    326.7 MiB    326.7 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    331.3 MiB      4.6 MiB           "images": _mat_feature(image_mat),
    57    331.3 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    331.3 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    331.3 MiB    331.3 MiB   @profile
    23                             def _mat_feature(mat):
    24    331.3 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    331.3 MiB    331.3 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    331.3 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    331.3 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    331.3 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.4 MiB    334.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.4 MiB    334.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.4 MiB    334.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    334.4 MiB    334.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    334.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.4 MiB    334.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.4 MiB    334.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    334.4 MiB    334.4 MiB   @profile
    23                             def _mat_feature(mat):
    24    334.4 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    334.4 MiB    334.4 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    334.4 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    334.4 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    334.4 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.2 MiB    337.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
WARNING: Logging before flag parsing goes to stderr.
I0830 20:19:54.528323 140534394648384 estimator.py:209] Using config: {'_model_dir': '/opt/tf_issue_32052/data/east_net', '_tf_random_seed': None, '_save_summary_steps': 2.0, '_save_checkpoints_steps': 6.0, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  allow_growth: true
}
allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 2.0, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd01fb0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0830 20:19:54.529422 140534394648384 model_fn.py:630] Estimator's model_fn (<east_model.EASTTFModel object at 0x7fd0b4e9e4e0>) includes params argument, but params are not passed to Estimator.
I0830 20:19:54.530229 140534394648384 print_helper.py:59] [92m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[0m
W0830 20:19:54.530515 140534394648384 print_helper.py:77] [93mMemory used is 316.20703125[0m
I0830 20:19:54.530762 140534394648384 print_helper.py:59] [92m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<[0m
================================================
    22    337.2 MiB    337.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.2 MiB    337.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.0 MiB    337.0 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.2 MiB      0.2 MiB           "images": _mat_feature(image_mat),
    57    337.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.2 MiB    337.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.2 MiB    337.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    22    337.2 MiB    337.2 MiB   @profile
    23                             def _mat_feature(mat):
    24    337.2 MiB      0.0 MiB       return tf.train.Feature(float_list=tf.train.FloatList(value=mat.flatten()))


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    50    337.2 MiB    337.2 MiB   @profile
    51                             def _get_east_features(image_mat, score_map_mat, geo_map_mat):
    52                                 """
    53                                 Given different features matrices, this routine wraps the matrices as TF features
    54                                 """
    55                                 return {
    56    337.2 MiB      0.0 MiB           "images": _mat_feature(image_mat),
    57    337.2 MiB      0.0 MiB           "score_maps": _mat_feature(score_map_mat),
    58    337.2 MiB      0.0 MiB           "geo_maps": _mat_feature(geo_map_mat),
    59                                 }


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
    95    321.0 MiB    321.0 MiB   @profile
    96                             def generate_image_tf_records(number_files, out_dir):
    97                             
    98    321.0 MiB      0.0 MiB       if not os.path.exists(out_dir):
    99    321.0 MiB      0.0 MiB           os.makedirs(out_dir)
   100                             
   101    340.4 MiB      0.0 MiB       for i in tqdm(range(number_files)):
   102    340.4 MiB      0.0 MiB           file_path_name = os.path.join(out_dir, str(i) + ".tfrecords")
   103    340.4 MiB      0.0 MiB           print(f"Writing to {file_path_name}")
   104    340.4 MiB      0.0 MiB           if os.path.exists(file_path_name):
   105                                         print(f"Found : {file_path_name}")
   106                                         continue
   107    340.4 MiB      0.0 MiB           with tf.io.TFRecordWriter(file_path_name) as writer:
   108    340.6 MiB      0.0 MiB               for i in range(NUM_SAMPLES_PER_FILE):
   109    340.4 MiB      5.1 MiB                   image_mat = np.random.rand(512, 512, 3)
   110    340.4 MiB      0.0 MiB                   score_map_mat = np.random.rand(128, 128, 1)
   111    340.4 MiB      0.0 MiB                   geo_map_mat = np.random.rand(128, 128, 5)
   112    340.4 MiB      0.0 MiB                   features = tf.train.Features(
   113    340.6 MiB      3.1 MiB                       feature=_get_east_features(image_mat, score_map_mat, geo_map_mat))
   114    340.6 MiB      0.3 MiB                   example = tf.train.Example(features=features)
   115    340.6 MiB      0.0 MiB                   writer.write(example.SerializeToString())


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    41    316.2 MiB    316.2 MiB   @profile
    42                             def _init_tf_config(clear_model_data=False,
    43                                                 save_checkpoints_steps=TOTAL_STEPS_PER_FILE * 3,
    44                                                 # each TFRecord file has NUM_SAMPLE, so for every 3 TFRecord files store the checkpoint
    45                                                 keep_checkpoint_max=5,
    46                                                 save_summary_steps=TOTAL_STEPS_PER_FILE * 1,
    47                                                 log_step_count_steps=TOTAL_STEPS_PER_FILE * 1):
    48                             
    49    316.2 MiB      0.0 MiB       run_config = tf.compat.v1.ConfigProto()
    50    316.2 MiB      0.0 MiB       run_config.gpu_options.allow_growth = True
    51                                 # run_config.gpu_options.per_process_gpu_memory_fraction = 0.50
    52    316.2 MiB      0.0 MiB       run_config.allow_soft_placement = True
    53    316.2 MiB      0.0 MiB       run_config.log_device_placement = False
    54    316.2 MiB      0.0 MiB       model_dir = MODEL_DIR
    55                             
    56    316.2 MiB      0.0 MiB       if clear_model_data:
    57                                     if os.path.exists(model_dir):
    58                                         shutil.rmtree(model_dir)
    59                             
    60    316.2 MiB      0.0 MiB       _run_config = tf.estimator.RunConfig(session_config=run_config,
    61    316.2 MiB      0.0 MiB                                            save_checkpoints_steps=save_checkpoints_steps,
    62    316.2 MiB      0.0 MiB                                            keep_checkpoint_max=keep_checkpoint_max,
    63    316.2 MiB      0.0 MiB                                            save_summary_steps=save_summary_steps,
    64    316.2 MiB      0.0 MiB                                            model_dir=model_dir,
    65    316.2 MiB      0.0 MiB                                            log_step_count_steps=log_step_count_steps)
    66                             
    67    316.2 MiB      0.0 MiB       return _run_config


objgraph growth list
function                         63338    +63338
dict                             34721    +34721
tuple                            31294    +31294
list                             16015    +16015
cell                             14514    +14514
weakref                           9896     +9896
type                              6925     +6925
getset_descriptor                 6505     +6505
property                          4967     +4967
builtin_function_or_method        3901     +3901
ModuleSpec                        3452     +3452
module                            3449     +3449
wrapper_descriptor                3350     +3350
  0%|          | 0/3 [00:00<?, ?it/s]E0830 20:19:55.931241 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch[0m
I0830 20:19:55.931848 140534394648384 print_helper.py:59] [92m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[0m
W0830 20:19:55.932131 140534394648384 print_helper.py:77] [93mMemory used is 316.2421875[0m
I0830 20:19:55.932413 140534394648384 print_helper.py:59] [92m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<[0m
E0830 20:19:55.932952 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Training[0m
W0830 20:19:56.168122 140534394648384 deprecation.py:506] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0830 20:19:56.170490 140534394648384 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
2019-08-30 20:19:56.312640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-08-30 20:19:56.367554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:19:56.368094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:19:56.421967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:19:56.470019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:19:56.576231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:19:56.603772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:19:56.635983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:19:56.707428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:19:56.862281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:19:56.862711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:19:56.864455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:19:56.865980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
W0830 20:20:19.647225 140534394648384 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fd022147e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 139>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
W0830 20:20:19.711404 140534394648384 deprecation.py:323] From /opt/tf_issue_32052/dummy_datasets.py:192: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
I0830 20:20:19.876526 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:20:19.877214 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:1", shape=(None, 512, 512, 3), dtype=float32, device=/device:CPU:0)[0m
W0830 20:20:19.914484 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:20:19.915208 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, 512, 512, 3), dtype=float32)[0m
W0830 20:20:19.928825 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, 518, 518, 3), dtype=float32)[0m
W0830 20:20:20.288528 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:20:20.700384 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:20:20.714737 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:20:20.726944 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, 258, 258, 64), dtype=float32)[0m
W0830 20:20:20.810297 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
W0830 20:20:20.811310 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:20:20.812274 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:20:20.813451 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:20:20.814841 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:20.940917 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:21.362107 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:21.371021 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:21.530827 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:21.954088 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:21.962855 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:22.071138 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:22.494082 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:22.602074 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:23.029032 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:23.039556 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:23.048408 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:20:23.049046 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:20:23.049483 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:23.049970 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:23.164083 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:23.591399 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:23.600445 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:23.712970 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:24.138924 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:24.148038 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:24.257636 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:24.682624 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:24.692686 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:24.701316 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:20:24.701837 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:20:24.702244 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:24.702725 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:24.810770 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:25.216169 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:25.224488 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:25.325737 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:25.722667 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:25.730835 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:20:25.832227 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:26.275312 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:26.285608 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:26.294561 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:20:26.295125 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:20:26.295541 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:20:26.295952 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:20:26.296486 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:20:26.408361 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:26.832217 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:26.840668 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:26.944075 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:27.350024 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:27.358445 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:27.461156 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:27.870776 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:27.974084 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:28.374583 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:28.384094 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:28.392422 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:28.392942 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:28.393355 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:28.393819 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:28.496036 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:28.902599 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:28.910945 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:29.016056 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:29.437477 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:29.446245 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:29.553808 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:30.044188 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:30.054287 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:30.062956 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:30.063520 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:30.063938 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:30.064421 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:30.172751 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:30.594229 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:30.603007 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:30.710875 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:31.130038 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:31.138734 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:31.246162 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:31.664668 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:31.674688 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:31.683478 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:31.684016 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:31.684425 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:31.684913 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:31.792368 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:32.211878 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:32.220649 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:32.328150 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:32.748596 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:32.757343 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:20:32.865343 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:33.268974 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:33.278431 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:33.286813 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:33.287338 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:20:33.287714 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:20:33.288085 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:20:33.288529 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:20:33.391180 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:33.793393 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:33.801812 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:33.905435 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:34.305101 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:34.313409 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:34.423841 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:34.855720 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:34.966569 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:35.426278 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:35.438411 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:35.448205 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:35.448801 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:35.449263 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:35.449806 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:35.575429 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:36.086463 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:36.097239 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:36.231650 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:36.751952 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:36.762768 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:36.906758 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:37.449099 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:37.460660 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:37.470649 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:37.471277 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:37.471751 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:37.472310 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:37.596790 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:38.078533 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:38.088633 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:38.213505 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:38.757931 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:38.767775 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:38.902859 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:39.415230 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:39.426615 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:39.436544 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:39.437159 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:39.437633 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:39.438195 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:39.562638 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:40.046297 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:40.056099 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:40.177138 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:40.658064 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:40.668037 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:40.802597 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:41.324227 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:41.335122 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:41.344575 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:41.345160 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:41.345606 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:41.346132 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:41.463161 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:41.933306 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:41.943125 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:42.063853 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:42.544980 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:42.555214 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:42.690789 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:43.203278 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:43.214232 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:43.223649 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:43.224270 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:43.224719 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:43.225253 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:43.342508 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:43.806431 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:43.815963 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:43.932915 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:44.388294 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:44.398332 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:20:44.532428 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:45.101471 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:45.113426 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:45.123877 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:45.124503 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:20:45.124995 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:20:45.125493 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:20:45.126089 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:20:45.254106 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:45.729087 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:45.739134 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:45.862503 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:46.341067 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:46.350607 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:46.474800 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:46.982322 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:47.123002 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:47.645800 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:47.657551 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:47.667408 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:20:47.668025 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:20:47.668495 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:47.669048 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:47.794807 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:48.280216 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:48.290369 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:48.411630 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:48.876540 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:48.886500 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:49.018810 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:49.499166 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:49.509166 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:49.517767 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:20:49.518294 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:20:49.518702 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:20:49.519186 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:49.627608 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:50.102600 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:50.112126 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:50.227967 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:50.776635 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:50.787454 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:20:50.920045 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:51.463326 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:51.474087 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:51.483424 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:20:51.484001 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:20:51.484497 140534394648384 east_model.py:252] Shape of f_0 : (None, 16, 16, 2048)
I0830 20:20:51.484977 140534394648384 east_model.py:252] Shape of f_1 : (None, 32, 32, 1024)
I0830 20:20:51.485446 140534394648384 east_model.py:252] Shape of f_2 : (None, 64, 64, 512)
I0830 20:20:51.485913 140534394648384 east_model.py:252] Shape of f_3 : (None, 128, 128, 256)
I0830 20:20:51.553185 140534394648384 east_model.py:271] Shape of h_0 : (None, 16, 16, 2048), g_0 : (None, None, None, 2048)
I0830 20:20:51.896043 140534394648384 east_model.py:271] Shape of h_1 : (None, 32, 32, 128), g_1 : (None, None, None, 128)
I0830 20:20:52.239075 140534394648384 east_model.py:271] Shape of h_2 : (None, 64, 64, 64), g_2 : (None, None, None, 64)
I0830 20:20:52.599367 140534394648384 east_model.py:271] Shape of h_3 : (None, 128, 128, 32), g_3 : (None, 128, 128, 32)
E0830 20:20:52.956416 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:0", shape=(None, 128, 128, 5), dtype=float32, device=/device:CPU:0)[0m
E0830 20:20:52.957045 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:2", shape=(None, 128, 128, 1), dtype=float32, device=/device:CPU:0)[0m
E0830 20:20:52.957693 140534394648384 print_helper.py:68] [31mTensor("conv2d_7/Sigmoid:0", shape=(None, 128, 128, 1), dtype=float32)[0m
E0830 20:20:52.958331 140534394648384 print_helper.py:68] [31mTensor("concat_4:0", shape=(None, 128, 128, 5), dtype=float32)[0m
E0830 20:20:53.193251 140534394648384 print_helper.py:68] [31mTensor("add_28:0", shape=(), dtype=float32)[0m
W0830 20:20:55.296993 140534394648384 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0830 20:22:51.096955 140534394648384 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/model_fn.py:337: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.TensorShape([]).
I0830 20:22:51.097802 140534394648384 estimator.py:1147] Done calling model_fn.
I0830 20:22:51.106083 140534394648384 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
I0830 20:23:14.323669 140534394648384 monitored_session.py:240] Graph was finalized.
2019-08-30 20:23:14.324354: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-30 20:23:14.525265: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-08-30 20:23:14.540398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e147812300 executing computations on platform Host. Devices:
2019-08-30 20:23:14.540478: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-08-30 20:23:14.763179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:23:14.764529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e147755690 executing computations on platform CUDA. Devices:
2019-08-30 20:23:14.764584: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1060 with Max-Q Design, Compute Capability 6.1
2019-08-30 20:23:14.765095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:23:14.766373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:23:14.766488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:23:14.766548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:23:14.766675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:23:14.766758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:23:14.766858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:23:14.766920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:23:14.767015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:23:14.767236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:23:14.769871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:23:14.771013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:23:14.811275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:23:14.816119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:23:14.816186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:23:14.816207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:23:14.817051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:23:14.818373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:23:14.819542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:23:29.644833 140534394648384 session_manager.py:500] Running local_init_op.
I0830 20:23:30.052592 140534394648384 session_manager.py:502] Done running local_init_op.
I0830 20:24:35.889086 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /opt/tf_issue_32052/data/east_net/model.ckpt.
2019-08-30 20:24:48.430682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:24:52.996492: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-30 20:24:53.462079: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-30 20:24:53.470386: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
I0830 20:24:54.798972 140534394648384 basic_session_run_hooks.py:262] loss = 2.0182283, step = 0
I0830 20:25:03.554620 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 0.228363
I0830 20:25:03.556297 140534394648384 basic_session_run_hooks.py:260] loss = 1.9264733, step = 2 (8.757 sec)
I0830 20:25:04.333160 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 2.56887
I0830 20:25:04.334808 140534394648384 basic_session_run_hooks.py:260] loss = 1.9297013, step = 4 (0.779 sec)
I0830 20:25:04.726184 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 6 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:25:07.817351 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 0.574021
I0830 20:25:07.819093 140534394648384 basic_session_run_hooks.py:260] loss = 1.9032693, step = 6 (3.484 sec)
I0830 20:25:08.599229 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 2.55794
I0830 20:25:08.600933 140534394648384 basic_session_run_hooks.py:260] loss = 1.9047558, step = 8 (0.782 sec)
I0830 20:25:10.296993 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 10 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:25:13.744889 140534394648384 estimator.py:368] Loss for final step: 1.9010239.
E0830 20:25:13.748032 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Evaluating[0m
W0830 20:25:14.168146 140534394648384 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fd022147e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 139>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
SourceFileLoader                  3207     +3207
method_descriptor                 3152     +3152
set                               2688     +2688
TFDecorator                       1729     +1729
frozenset                         1543     +1543
ArgSpec                           1224     +1224
_OpInfo                           1224     +1224
method                            1174     +1174
classmethod                       1168     +1168
staticmethod                      1099     +1099
member_descriptor                  944      +944
TagMap                             803      +803
cython_function_or_method          608      +608
fused_cython_function              571      +571
ABCMeta                            562      +562
GeneratedProtocolMessageType       505      +505
MovedAttribute                     496      +496
FileFinder                         463      +463
vectorize                          454      +454
Parameter                          452      +452
NamedTypes                         410      +410
__pyx_scope_struct__with_phil      344      +344
TFModuleWrapper                    344      +344
FontEntry                          335      +335
PointerType                        334      +334
PathMetadata                       332      +332
DistInfoDistribution               325      +325
MiniProduction                     310      +310
MovedModule                        284      +284
NamedType                          251      +251
slice                              228      +228
Enum                               216      +216
And                                213      +213
TagSet                             199      +199
ExtensionFileLoader                192      +192
Tag                                160      +160
OrderedDict                        155      +155







Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    70    316.2 MiB    316.2 MiB   @profile
    71                             def _get_train_spec(max_steps=None):
    72                                 # Estimators expect an input_fn to take no arguments.
    73                                 # To work around this restriction, we use lambda to capture the arguments and provide the expected interface.
    74    316.2 MiB      0.0 MiB       return tf.estimator.TrainSpec(
    75    316.2 MiB      0.0 MiB           input_fn=lambda: _get_dataset(data_path=TRAIN_DATA),
    76    316.2 MiB      0.0 MiB           max_steps=max_steps,
    77    316.2 MiB      0.0 MiB           hooks=None)


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   161    356.4 MiB    356.4 MiB   @profile
   162                             def _get_dataset(data_path):
   163                                 """
   164                                 Reads TFRecords, decode and batches them
   165                                 :return: dataset
   166                                 """
   167    356.4 MiB      0.0 MiB       _num_cores = 4
   168    356.4 MiB      0.0 MiB       _batch_size = BATCH_SIZE
   169                             
   170    356.4 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   171    356.4 MiB      0.0 MiB       path = path.replace("//", "/")
   172    356.8 MiB      0.4 MiB       files = tf.data.Dataset.list_files(path)
   173                                 # files = glob.glob(pathname=path)
   174                             
   175                                 # TF dataset APIs
   176    356.8 MiB      0.0 MiB       dataset = files.interleave(
   177    356.8 MiB      0.0 MiB           tf.data.TFRecordDataset,
   178    356.8 MiB      0.0 MiB           cycle_length=_num_cores,
   179    357.2 MiB      0.4 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   180                             
   181                                 # dataset = tf.data.TFRecordDataset(files, num_parallel_reads=_num_cores)
   182                                 # dataset = dataset.shuffle(_batch_size*10, 42)
   183                                 # Map the generator output as features as a dict and label
   184                             
   185    357.2 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   186    359.9 MiB      2.6 MiB         dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   187                                 else:
   188                                   dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   189                             
   190    359.9 MiB      0.0 MiB       dataset = dataset.batch(batch_size=_batch_size, drop_remainder=False)
   191    359.9 MiB      0.0 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   192    359.8 MiB      0.0 MiB       iterator = dataset.make_one_shot_iterator()
   193    359.8 MiB      0.0 MiB       batch_feats, batch_label = iterator.get_next()
   194    359.8 MiB      0.0 MiB       return batch_feats, batch_label


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    88    316.2 MiB    316.2 MiB   @profile
    89                             def train(estimator, max_steps=None):
    90    316.2 MiB      0.0 MiB       train_spec = _get_train_spec(max_steps=max_steps)
    91    316.2 MiB      0.0 MiB       estimator.train(
    92    316.2 MiB      0.0 MiB           input_fn=train_spec.input_fn,
    93    316.2 MiB      0.0 MiB           hooks=train_spec.hooks,
    94   5728.4 MiB   5412.2 MiB           max_steps=train_spec.max_steps)


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    80   5728.4 MiB   5728.4 MiB   @profile
    81                             def _get_eval_spec(steps):
    82   5728.4 MiB      0.0 MiB       return tf.estimator.EvalSpec(
    83   5728.4 MiB      0.0 MiB           input_fn=lambda: _get_dataset(data_path=VAL_DATA),
    84   5728.4 MiB      0.0 MiB           steps=steps,
    85   5728.4 MiB      0.0 MiB           hooks=None)


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   161   5728.4 MiB   5728.4 MiB   @profile
   162                             def _get_dataset(data_path):
   163                                 """
   164                                 Reads TFRecords, decode and batches them
   165                                 :return: dataset
   166                                 """
   167   5728.4 MiB      0.0 MiB       _num_cores = 4
   168   5728.4 MiB      0.0 MiB       _batch_size = BATCH_SIZE
   169                             
   170   5728.4 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   171   5728.4 MiB      0.0 MiB       path = path.replace("//", "/")
   172   5728.4 MiB      0.0 MiB       files = tf.data.Dataset.list_files(path)
   173                                 # files = glob.glob(pathname=path)
   174                             
   175                                 # TF dataset APIs
   176   5728.4 MiB      0.0 MiB       dataset = files.interleave(
   177   5728.4 MiB      0.0 MiB           tf.data.TFRecordDataset,
   178   5728.4 MiB      0.0 MiB           cycle_length=_num_cores,
   179   5728.4 MiB      0.0 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   180                             
   181                                 # dataset = tf.data.TFRecordDataset(files, num_parallel_reads=_num_cores)
   182                                 # dataset = dataset.shuffle(_batch_size*10, 42)
   183                                 # Map the generator output as features as a dict and label
   184                             
   185   5728.4 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   186   5728.4 MiB      0.0 MiB         dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
I0830 20:25:14.395614 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:25:14.396289 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:1", shape=(None, 512, 512, 3), dtype=float32, device=/device:CPU:0)[0m
W0830 20:25:14.433876 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:25:14.434582 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, 512, 512, 3), dtype=float32)[0m
W0830 20:25:14.447600 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, 518, 518, 3), dtype=float32)[0m
W0830 20:25:14.552618 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:25:14.972404 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:25:14.981011 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:25:14.993693 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, 258, 258, 64), dtype=float32)[0m
W0830 20:25:15.004244 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
W0830 20:25:15.004659 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:25:15.005052 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:25:15.005434 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:25:15.005897 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:15.112489 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:15.524770 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:15.533277 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:15.638755 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:16.049669 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:16.058283 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:16.164476 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:16.593814 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:16.698382 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:17.107678 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:17.117601 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:17.125897 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:25:17.126402 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:25:17.126801 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:17.127272 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:17.231508 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:17.648765 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:17.657220 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:17.762235 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:18.171484 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:18.179993 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:18.284278 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:18.692754 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:18.702545 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:18.710841 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:25:18.711359 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:25:18.711751 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:18.712199 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:18.830508 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:19.239533 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:19.248211 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:19.353511 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:19.761269 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:19.769806 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:25:19.874218 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:20.285287 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:20.295009 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:20.303400 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:25:20.303906 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:25:20.304309 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:25:20.304710 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:25:20.305166 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:25:20.409267 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:20.819805 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:20.828351 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:20.932883 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:21.342578 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:21.351111 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:21.455382 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:21.865524 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:21.970053 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:22.380062 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:22.390006 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:22.398299 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:22.398812 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:22.399215 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:22.399694 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:22.504727 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:22.926414 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:22.934840 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:23.039264 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:23.448909 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:23.457446 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:23.562840 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:23.972990 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:23.982799 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:23.991217 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:23.991725 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:23.992124 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:23.992593 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:24.098348 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:24.509527 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:24.518121 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:24.623121 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:25.033119 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:25.041687 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:25.146793 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:25.559476 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:25.569226 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:25.577565 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:25.578073 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:25.578469 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:25.578938 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:25.684036 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:26.095060 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:26.103857 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:26.208533 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:26.620257 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:26.628870 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:25:26.733844 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:27.146846 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:27.156596 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:27.165004 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:27.165516 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:25:27.165909 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:25:27.166281 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:25:27.166807 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:25:27.271637 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:27.704369 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:27.712938 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:27.818466 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:28.230402 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:28.238947 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:28.352310 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:28.797448 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:28.911120 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:29.354974 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:29.364958 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:29.373417 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:29.373929 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:29.374328 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:29.374796 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:29.479412 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:29.891274 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:29.900154 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:30.005097 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:30.416860 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:30.425412 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:30.540251 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:30.987107 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:30.996938 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:31.005325 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:31.005835 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:31.006232 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:31.006702 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:31.112362 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:31.524467 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:31.532976 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:31.637964 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:32.050253 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:32.058996 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:32.172726 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:32.622517 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:32.632304 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:32.640694 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:32.641215 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:32.641643 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:32.642121 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:32.747244 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:33.160974 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:33.169563 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:33.275073 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:33.698817 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:33.707379 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:33.823667 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:34.268370 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:34.279244 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:34.287793 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:34.288303 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:34.288700 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:34.289176 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:34.395015 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:34.808828 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:34.817429 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:34.924097 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:35.336901 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:35.345468 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:35.464184 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:35.911016 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:35.920685 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:35.929137 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:35.929659 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:35.930062 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:35.930519 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:36.036399 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:36.447922 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:36.456489 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:36.562350 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:36.976043 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:36.984631 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:25:37.099327 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:37.562932 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:37.573344 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:37.581783 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:37.582294 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:25:37.582701 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:25:37.583103 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:25:37.583582 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:25:37.692797 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:38.121228 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:38.130209 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:38.238521 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:39.069010 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:39.077920 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:39.195199 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:39.654575 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:39.772210 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:40.231308 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:40.241490 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:40.250115 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:25:40.250621 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:25:40.251024 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:40.251508 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:40.360161 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:40.785115 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:40.793895 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:40.901732 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:41.323478 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:41.332049 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:41.445514 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:41.890700 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:41.900497 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:41.908952 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:25:41.909460 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:25:41.909855 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:25:41.910321 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:42.016538 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:42.430810 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:42.439589 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:42.550302 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:42.965942 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:42.974532 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:25:43.088751 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:43.536444 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:43.546294 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:43.554663 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:25:43.555174 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:25:43.555630 140534394648384 east_model.py:252] Shape of f_0 : (None, 16, 16, 2048)
I0830 20:25:43.556066 140534394648384 east_model.py:252] Shape of f_1 : (None, 32, 32, 1024)
I0830 20:25:43.556499 140534394648384 east_model.py:252] Shape of f_2 : (None, 64, 64, 512)
I0830 20:25:43.556939 140534394648384 east_model.py:252] Shape of f_3 : (None, 128, 128, 256)
I0830 20:25:43.619768 140534394648384 east_model.py:271] Shape of h_0 : (None, 16, 16, 2048), g_0 : (None, None, None, 2048)
I0830 20:25:43.910520 140534394648384 east_model.py:271] Shape of h_1 : (None, 32, 32, 128), g_1 : (None, None, None, 128)
I0830 20:25:44.200454 140534394648384 east_model.py:271] Shape of h_2 : (None, 64, 64, 64), g_2 : (None, None, None, 64)
I0830 20:25:44.539721 140534394648384 east_model.py:271] Shape of h_3 : (None, 128, 128, 32), g_3 : (None, 128, 128, 32)
E0830 20:25:44.889541 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:0", shape=(None, 128, 128, 5), dtype=float32, device=/device:CPU:0)[0m
E0830 20:25:44.890175 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:2", shape=(None, 128, 128, 1), dtype=float32, device=/device:CPU:0)[0m
E0830 20:25:44.890830 140534394648384 print_helper.py:68] [31mTensor("conv2d_7/Sigmoid:0", shape=(None, 128, 128, 1), dtype=float32)[0m
E0830 20:25:44.891503 140534394648384 print_helper.py:68] [31mTensor("concat_4:0", shape=(None, 128, 128, 5), dtype=float32)[0m
E0830 20:25:45.127356 140534394648384 print_helper.py:68] [31mTensor("add_28:0", shape=(), dtype=float32)[0m
I0830 20:27:46.908104 140534394648384 estimator.py:1147] Done calling model_fn.
I0830 20:27:47.101795 140534394648384 evaluation.py:255] Starting evaluation at 2019-08-30T20:27:47Z
I0830 20:28:04.392236 140534394648384 monitored_session.py:240] Graph was finalized.
2019-08-30 20:28:04.393110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:28:04.393780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:28:04.393821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:28:04.393834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:28:04.393847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:28:04.393859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:28:04.393871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:28:04.393891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:28:04.393908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:28:04.393960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:28:04.394568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:28:04.395134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:28:04.395157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:28:04.395163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:28:04.395167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:28:04.395289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:28:04.395896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:28:04.396475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:28:04.397290 140534394648384 saver.py:1284] Restoring parameters from /opt/tf_issue_32052/data/east_net/model.ckpt-10
I0830 20:28:07.820496 140534394648384 session_manager.py:500] Running local_init_op.
I0830 20:28:08.249796 140534394648384 session_manager.py:502] Done running local_init_op.
I0830 20:28:11.841895 140534394648384 evaluation.py:275] Finished evaluation at 2019-08-30-20:28:11
I0830 20:28:11.842442 140534394648384 estimator.py:2039] Saving dict for global step 10: global_step = 10, loss = 1.9114864
I0830 20:28:17.218111 140534394648384 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10: /opt/tf_issue_32052/data/east_net/model.ckpt-10
 33%|███▎      | 1/3 [08:46<17:33, 526.91s/it]E0830 20:28:42.844893 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch[0m
I0830 20:28:42.845570 140534394648384 print_helper.py:59] [92m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[0m
W0830 20:28:42.845872 140534394648384 print_helper.py:77] [93mMemory used is 8307.99609375[0m
I0830 20:28:42.846153 140534394648384 print_helper.py:59] [92m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<[0m
E0830 20:28:42.846727 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Training[0m
W0830 20:28:43.338040 140534394648384 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fd022147e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 139>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
I0830 20:28:43.621980 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:28:43.623369 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:1", shape=(None, 512, 512, 3), dtype=float32, device=/device:CPU:0)[0m
W0830 20:28:43.666718 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:28:43.667516 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, 512, 512, 3), dtype=float32)[0m
W0830 20:28:43.682372 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, 518, 518, 3), dtype=float32)[0m
W0830 20:28:43.810009 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:28:44.354045 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:28:44.365572 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:28:44.381975 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, 258, 258, 64), dtype=float32)[0m
W0830 20:28:44.395928 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
W0830 20:28:44.396427 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:28:44.396880 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:28:44.397345 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:28:44.398183 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:44.527252 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:44.996730 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:45.007416 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:45.138498 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:45.661794 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:45.672267 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:45.799630 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:46.278527 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:46.401379 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:46.918953 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:46.930741 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:46.941483 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:28:46.942048 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:28:46.942492 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:28:46.943014 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:47.071586 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:47.553492 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:47.563920 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:47.686476 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:48.163949 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:48.173658 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:48.296303 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:48.776287 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:48.787988 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:48.797543 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:28:48.798180 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:28:48.798913 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:28:48.799709 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:48.921658 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:49.400849 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:49.410525 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:49.532727 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:49.992803 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:50.002713 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:28:50.122453 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:50.583063 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:50.594367 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:50.603587 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:28:50.604093 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:28:50.604484 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:28:50.604878 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:28:50.605366 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:28:50.725286 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:51.183815 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:51.193182 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:51.311948 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:51.777679 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:51.787015 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:51.906403 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:52.367648 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:52.485538 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:52.946769 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:52.957561 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:52.967357 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:52.968216 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:52.968615 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:28:52.969090 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:53.088565 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:53.543854 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:53.554173 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:53.676720 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:54.154444 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:54.163467 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:54.281973 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:54.719383 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:54.729643 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:54.738438 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:54.738985 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:54.739416 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:28:54.739912 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:54.850153 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:55.300533 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:55.309490 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:55.423925 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:55.861532 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:55.870571 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:55.981068 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:56.419508 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:56.429735 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:56.438521 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:56.439058 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:56.439475 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:28:56.439968 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:56.553714 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:56.988739 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:56.997786 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:57.108069 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:57.539953 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:57.549312 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:28:57.668292 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:58.138057 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:58.149254 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:58.158876 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:58.159464 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:28:58.159919 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:28:58.160371 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:28:58.160918 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:28:58.281282 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:28:58.755305 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:28:58.765133 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:28:58.887308 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:28:59.372048 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:28:59.381876 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:28:59.512253 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:00.030334 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:00.165812 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:00.684304 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:00.696074 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:00.706064 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:00.706673 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:00.707145 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:00.707711 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:00.831746 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:01.318350 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:01.328141 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:01.452082 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:01.916730 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:01.926356 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:02.053249 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:02.556534 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:02.567457 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:02.576868 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:02.577437 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:02.577881 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:02.578408 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:02.695741 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:03.151965 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:03.161497 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:03.278817 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:03.737079 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:03.747035 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:03.892899 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:04.453800 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:04.464631 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:04.473992 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:04.474553 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:04.474997 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:04.475521 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:04.606083 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:05.067904 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:05.079225 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:05.216313 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:05.718197 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:05.727880 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:05.854539 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:06.341206 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:06.351914 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:06.362037 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:06.362607 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:06.363036 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:06.363543 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:06.489062 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:07.015388 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:07.028241 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:07.167222 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:07.710154 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:07.721980 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:07.872941 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:08.368867 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:08.379455 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:08.388487 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:08.389037 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:08.389468 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:08.389976 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:08.503586 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:08.936141 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:08.945181 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:09.055581 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:09.490001 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:09.499047 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:29:09.621591 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:10.113756 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:10.124732 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:10.134258 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:10.134830 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:29:10.135268 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:29:10.135702 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:29:10.136221 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:29:10.253567 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:10.722273 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:10.733660 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:10.881521 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:11.427620 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:11.438213 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:11.581899 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:12.127381 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:12.268155 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:12.848040 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:12.860970 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:12.872623 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:29:12.873209 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:29:12.873836 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:12.874866 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:13.008335 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:13.521987 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:13.533129 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:13.666703 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:14.194567 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:14.204555 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:14.339274 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:14.867019 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:14.878190 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:14.888402 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:29:14.888941 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:29:14.889358 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:29:14.889853 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:15.015218 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:15.501994 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:15.511753 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:15.633729 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:16.103855 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:16.114364 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:29:16.262722 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:16.821403 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:16.834301 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:16.844946 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:29:16.845539 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:29:16.846132 140534394648384 east_model.py:252] Shape of f_0 : (None, 16, 16, 2048)
I0830 20:29:16.846901 140534394648384 east_model.py:252] Shape of f_1 : (None, 32, 32, 1024)
I0830 20:29:16.847747 140534394648384 east_model.py:252] Shape of f_2 : (None, 64, 64, 512)
I0830 20:29:16.848305 140534394648384 east_model.py:252] Shape of f_3 : (None, 128, 128, 256)
I0830 20:29:16.930163 140534394648384 east_model.py:271] Shape of h_0 : (None, 16, 16, 2048), g_0 : (None, None, None, 2048)
I0830 20:29:17.272460 140534394648384 east_model.py:271] Shape of h_1 : (None, 32, 32, 128), g_1 : (None, None, None, 128)
I0830 20:29:17.647489 140534394648384 east_model.py:271] Shape of h_2 : (None, 64, 64, 64), g_2 : (None, None, None, 64)
I0830 20:29:18.051565 140534394648384 east_model.py:271] Shape of h_3 : (None, 128, 128, 32), g_3 : (None, 128, 128, 32)
E0830 20:29:18.443800 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:0", shape=(None, 128, 128, 5), dtype=float32, device=/device:CPU:0)[0m
E0830 20:29:18.444422 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:2", shape=(None, 128, 128, 1), dtype=float32, device=/device:CPU:0)[0m
E0830 20:29:18.445076 140534394648384 print_helper.py:68] [31mTensor("conv2d_7/Sigmoid:0", shape=(None, 128, 128, 1), dtype=float32)[0m
E0830 20:29:18.445857 140534394648384 print_helper.py:68] [31mTensor("concat_4:0", shape=(None, 128, 128, 5), dtype=float32)[0m
E0830 20:29:18.730369 140534394648384 print_helper.py:68] [31mTensor("add_28:0", shape=(), dtype=float32)[0m
I0830 20:31:27.777554 140534394648384 estimator.py:1147] Done calling model_fn.
I0830 20:31:27.786088 140534394648384 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
I0830 20:31:46.036334 140534394648384 monitored_session.py:240] Graph was finalized.
2019-08-30 20:31:46.037507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:31:46.038179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:31:46.038220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:31:46.038233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:31:46.038245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:31:46.038258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:31:46.038270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:31:46.038282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:31:46.038294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:31:46.038348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:31:46.038858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:31:46.039220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:31:46.039241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:31:46.039246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:31:46.039251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:31:46.039367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:31:46.039770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:31:46.040141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:31:46.042875 140534394648384 saver.py:1284] Restoring parameters from /opt/tf_issue_32052/data/east_net/model.ckpt-10
W0830 20:31:48.395038 140534394648384 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
I0830 20:31:49.612802 140534394648384 session_manager.py:500] Running local_init_op.
I0830 20:31:50.038802 140534394648384 session_manager.py:502] Done running local_init_op.
I0830 20:33:00.928442 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 10 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:33:16.600975 140534394648384 basic_session_run_hooks.py:262] loss = 1.9114431, step = 10
I0830 20:33:25.576480 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 0.222799
I0830 20:33:25.578085 140534394648384 basic_session_run_hooks.py:260] loss = 1.9064363, step = 12 (8.977 sec)
I0830 20:33:26.360881 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 2.54974
I0830 20:33:26.362450 140534394648384 basic_session_run_hooks.py:260] loss = 1.9265637, step = 14 (0.784 sec)
I0830 20:33:26.752866 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 16 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:33:29.888533 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 0.566949
I0830 20:33:29.890135 140534394648384 basic_session_run_hooks.py:260] loss = 1.9007215, step = 16 (3.528 sec)
I0830 20:33:30.666495 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 2.5708
I0830 20:33:30.668105 140534394648384 basic_session_run_hooks.py:260] loss = 1.9163101, step = 18 (0.778 sec)
I0830 20:33:31.092530 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 20 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:33:34.762826 140534394648384 estimator.py:368] Loss for final step: 1.9208405.
E0830 20:33:34.766452 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Evaluating[0m
W0830 20:33:35.187686 140534394648384 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fd022147e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 139>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
   187                                 else:
   188                                   dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   189                             
   190   5728.4 MiB      0.0 MiB       dataset = dataset.batch(batch_size=_batch_size, drop_remainder=False)
   191   5728.4 MiB      0.0 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   192   5728.4 MiB      0.0 MiB       iterator = dataset.make_one_shot_iterator()
   193   5728.4 MiB      0.0 MiB       batch_feats, batch_label = iterator.get_next()
   194   5728.4 MiB      0.0 MiB       return batch_feats, batch_label


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    97   5728.4 MiB   5728.4 MiB   @profile
    98                             def evaluate(estimator, steps=None, checkpoint_path=None):
    99   5728.4 MiB      0.0 MiB       eval_spec = _get_eval_spec(steps=steps)
   100   5728.4 MiB      0.0 MiB       estimator.evaluate(
   101   5728.4 MiB      0.0 MiB           input_fn=eval_spec.input_fn,
   102   5728.4 MiB      0.0 MiB           steps=eval_spec.steps,
   103   5728.4 MiB      0.0 MiB           hooks=eval_spec.hooks,
   104   8308.0 MiB   2579.6 MiB           checkpoint_path=checkpoint_path)


objgraph growth list after iteration 0
tuple                       2063391  +2032097
list                         687197   +671182
dict                         357922   +323201
set                           69397    +66709
Tensor                        60054    +60054
TF_Output                     59842    +59842
Operation                     59175    +59175
_InputList                    59175    +59175
ScopedTFFunction              58602    +58602
_DefinedFunction              57030    +57030
TensorShape                   56651    +56648
Dimension                     47649    +47647
TraceableObject               45426    +45426
builtin_function_or_method    11398     +7497
TraceableStack                 7144     +7144
weakref                       16329     +6433
OrderedDict                    5723     +5568
ResourceVariable               2077     +2077
deque                          1812     +1798
Condition                      1828     +1796
_local                         1797     +1786
ObjectIdentityWeakSet          1786     +1786
GroupLock                      1786     +1786
ObjectIdentitySet              1786     +1786
ScopedTFGraph                  1786     +1786
_WeakObjectIdentityWrapper     1777     +1777
_EagerDefinedFunction          1572     +1572
CondBranchFuncGraph            1354     +1354
cell                          14853      +339
FuncGraph                       218      +218
_CondGradFuncGraph              212      +212
LineLocation                    204      +204
_ObjectIdentityWrapper          138      +138
function                      63463      +125
OriginInfo                      111      +111
Location                        111      +111
TensorSpec                       28       +26
_VariantTracker                  24       +24
TrackableReference               24       +24
CapturableResourceDeleter        24       +24
weakproxy                        24       +24
module                         3465       +16
ModuleSpec                     3467       +15
SourceFileLoader               3222       +15
type                           6938       +13
TextIOWrapper                    16       +12
IncrementalEncoder               15       +12
FileIO                           16       +12
BufferedWriter                   15       +12
_TemporaryFileWrapper            12       +12







Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    70   8308.0 MiB   8308.0 MiB   @profile
    71                             def _get_train_spec(max_steps=None):
    72                                 # Estimators expect an input_fn to take no arguments.
    73                                 # To work around this restriction, we use lambda to capture the arguments and provide the expected interface.
    74   8308.0 MiB      0.0 MiB       return tf.estimator.TrainSpec(
    75   8308.0 MiB      0.0 MiB           input_fn=lambda: _get_dataset(data_path=TRAIN_DATA),
    76   8308.0 MiB      0.0 MiB           max_steps=max_steps,
    77   8308.0 MiB      0.0 MiB           hooks=None)


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   161   8308.0 MiB   8308.0 MiB   @profile
   162                             def _get_dataset(data_path):
   163                                 """
   164                                 Reads TFRecords, decode and batches them
   165                                 :return: dataset
   166                                 """
   167   8308.0 MiB      0.0 MiB       _num_cores = 4
   168   8308.0 MiB      0.0 MiB       _batch_size = BATCH_SIZE
   169                             
   170   8308.0 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   171   8308.0 MiB      0.0 MiB       path = path.replace("//", "/")
   172   8308.0 MiB      0.0 MiB       files = tf.data.Dataset.list_files(path)
   173                                 # files = glob.glob(pathname=path)
   174                             
   175                                 # TF dataset APIs
   176   8308.0 MiB      0.0 MiB       dataset = files.interleave(
   177   8308.0 MiB      0.0 MiB           tf.data.TFRecordDataset,
   178   8308.0 MiB      0.0 MiB           cycle_length=_num_cores,
   179   8308.0 MiB      0.0 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   180                             
   181                                 # dataset = tf.data.TFRecordDataset(files, num_parallel_reads=_num_cores)
   182                                 # dataset = dataset.shuffle(_batch_size*10, 42)
   183                                 # Map the generator output as features as a dict and label
   184                             
   185   8308.0 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   186   8308.0 MiB      0.0 MiB         dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   187                                 else:
   188                                   dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   189                             
   190   8308.0 MiB      0.0 MiB       dataset = dataset.batch(batch_size=_batch_size, drop_remainder=False)
   191   8308.0 MiB      0.0 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   192   8308.0 MiB      0.0 MiB       iterator = dataset.make_one_shot_iterator()
   193   8308.0 MiB      0.0 MiB       batch_feats, batch_label = iterator.get_next()
   194   8308.0 MiB      0.0 MiB       return batch_feats, batch_label


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    88   8308.0 MiB   8308.0 MiB   @profile
    89                             def train(estimator, max_steps=None):
    90   8308.0 MiB      0.0 MiB       train_spec = _get_train_spec(max_steps=max_steps)
    91   8308.0 MiB      0.0 MiB       estimator.train(
    92   8308.0 MiB      0.0 MiB           input_fn=train_spec.input_fn,
    93   8308.0 MiB      0.0 MiB           hooks=train_spec.hooks,
    94  11068.5 MiB   2760.5 MiB           max_steps=train_spec.max_steps)


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    80  11068.5 MiB  11068.5 MiB   @profile
    81                             def _get_eval_spec(steps):
    82  11068.5 MiB      0.0 MiB       return tf.estimator.EvalSpec(
    83  11068.5 MiB      0.0 MiB           input_fn=lambda: _get_dataset(data_path=VAL_DATA),
    84  11068.5 MiB      0.0 MiB           steps=steps,
    85  11068.5 MiB      0.0 MiB           hooks=None)


Filename: /opt/tf_issue_32052/dummy_datasets.py

I0830 20:33:35.472966 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:33:35.473871 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:1", shape=(None, 512, 512, 3), dtype=float32, device=/device:CPU:0)[0m
W0830 20:33:35.524476 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:33:35.525277 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, 512, 512, 3), dtype=float32)[0m
W0830 20:33:35.541741 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, 518, 518, 3), dtype=float32)[0m
W0830 20:33:35.662803 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:33:36.128663 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:33:36.138353 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:33:36.152765 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, 258, 258, 64), dtype=float32)[0m
W0830 20:33:36.164747 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
W0830 20:33:36.165227 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:33:36.165648 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:33:36.166059 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:33:36.166565 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:36.284343 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:36.726940 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:36.736159 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:36.850538 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:37.294749 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:37.304202 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:37.418329 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:37.863935 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:37.977766 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:38.421729 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:38.432466 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:38.441723 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:33:38.442264 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:33:38.442682 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:38.443169 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:38.556913 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:38.999247 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:39.008251 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:39.119710 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:39.570581 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:39.579974 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:39.693602 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:40.128263 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:40.138607 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:40.147431 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:33:40.147959 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:33:40.148355 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:40.148957 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:40.260873 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:40.706548 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:40.715709 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:40.829151 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:41.270549 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:41.279714 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:33:41.392458 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:41.831028 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:41.841363 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:41.850340 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:33:41.850896 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:33:41.851306 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:33:41.851711 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:33:41.852189 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:33:41.965007 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:42.398800 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:42.407808 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:42.518386 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:42.951374 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:42.960401 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:43.070702 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:43.506393 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:43.618194 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:44.051910 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:44.062287 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:44.071093 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:44.071645 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:44.072056 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:44.072540 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:44.184094 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:44.643598 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:44.652784 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:44.766451 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:45.215963 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:45.225024 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:45.337903 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:45.773731 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:45.784023 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:45.793153 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:45.793712 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:45.794125 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:45.794632 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:45.906785 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:46.341818 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:46.350870 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:46.463561 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:46.899224 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:46.908205 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:47.019937 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:47.457637 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:47.467930 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:47.477014 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:47.477553 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:47.477967 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:47.478454 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:47.594386 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:48.047616 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:48.056661 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:48.169487 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:48.608210 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:48.617259 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:33:48.729611 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:49.167473 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:49.177813 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:49.187008 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:49.187587 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:33:49.187998 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:33:49.188406 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:33:49.188895 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:33:49.301167 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:49.740421 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:49.749818 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:49.865568 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:50.310063 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:50.319316 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:50.442692 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:50.921524 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:51.046948 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:51.530603 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:51.541420 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:51.550394 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:51.550930 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:51.551367 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:51.551875 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:51.666939 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:52.112892 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:52.122296 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:52.238092 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:52.684331 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:52.693452 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:53.766943 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:54.541320 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:54.558406 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:54.573059 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:54.573958 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:54.574666 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:54.575536 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:54.757960 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:55.470725 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:55.485689 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:55.669990 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:56.384213 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:56.399168 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:56.598494 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:57.370417 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:57.387458 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:57.403323 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:57.404216 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:57.405027 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:57.405855 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:57.589992 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:58.120909 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:58.130781 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:58.253753 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:58.732988 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:58.742856 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:33:58.879117 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:59.395889 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:59.407676 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:59.417410 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:59.418010 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:33:59.418473 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:33:59.419351 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:33:59.542212 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:00.019132 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:00.029024 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:00.152519 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:00.628756 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:00.638596 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:00.772327 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:01.370206 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:01.384011 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:01.396782 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:34:01.397715 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:34:01.398289 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:34:01.398955 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:01.551289 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:02.176837 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:02.189844 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:02.352916 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:02.993630 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:03.007418 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:34:03.192771 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:03.887861 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:03.904228 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:03.918185 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:03.919054 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:34:03.919691 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:34:03.920315 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:34:03.921076 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:34:04.089952 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:04.885676 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:04.902425 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:05.098319 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:05.847098 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:05.861175 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:06.046297 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:06.746488 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:06.913742 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:07.565757 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:07.580292 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:07.593565 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:34:07.594402 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:34:07.595032 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:34:07.595727 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:07.751025 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:08.359911 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:08.372418 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:08.526646 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:09.127588 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:09.139974 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:09.306706 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:09.949400 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:09.963083 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:09.974664 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:34:09.975338 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:34:09.976065 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:34:09.977227 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:10.121414 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:10.690484 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:10.702037 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:10.847413 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:11.417405 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:11.428985 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:34:11.586156 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:12.183531 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:12.196302 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:12.207627 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:34:12.208283 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:34:12.208880 140534394648384 east_model.py:252] Shape of f_0 : (None, 16, 16, 2048)
I0830 20:34:12.209447 140534394648384 east_model.py:252] Shape of f_1 : (None, 32, 32, 1024)
I0830 20:34:12.210009 140534394648384 east_model.py:252] Shape of f_2 : (None, 64, 64, 512)
I0830 20:34:12.210571 140534394648384 east_model.py:252] Shape of f_3 : (None, 128, 128, 256)
I0830 20:34:12.296052 140534394648384 east_model.py:271] Shape of h_0 : (None, 16, 16, 2048), g_0 : (None, None, None, 2048)
I0830 20:34:12.679774 140534394648384 east_model.py:271] Shape of h_1 : (None, 32, 32, 128), g_1 : (None, None, None, 128)
I0830 20:34:13.075929 140534394648384 east_model.py:271] Shape of h_2 : (None, 64, 64, 64), g_2 : (None, None, None, 64)
I0830 20:34:13.530606 140534394648384 east_model.py:271] Shape of h_3 : (None, 128, 128, 32), g_3 : (None, 128, 128, 32)
E0830 20:34:13.999832 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:0", shape=(None, 128, 128, 5), dtype=float32, device=/device:CPU:0)[0m
E0830 20:34:14.000662 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:2", shape=(None, 128, 128, 1), dtype=float32, device=/device:CPU:0)[0m
E0830 20:34:14.001604 140534394648384 print_helper.py:68] [31mTensor("conv2d_7/Sigmoid:0", shape=(None, 128, 128, 1), dtype=float32)[0m
E0830 20:34:14.002446 140534394648384 print_helper.py:68] [31mTensor("concat_4:0", shape=(None, 128, 128, 5), dtype=float32)[0m
E0830 20:34:14.301213 140534394648384 print_helper.py:68] [31mTensor("add_28:0", shape=(), dtype=float32)[0m
I0830 20:36:14.770366 140534394648384 estimator.py:1147] Done calling model_fn.
I0830 20:36:14.949520 140534394648384 evaluation.py:255] Starting evaluation at 2019-08-30T20:36:14Z
I0830 20:36:33.220554 140534394648384 monitored_session.py:240] Graph was finalized.
2019-08-30 20:36:33.221667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:36:33.222326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:36:33.222365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:36:33.222379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:36:33.222391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:36:33.222404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:36:33.222417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:36:33.222429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:36:33.222441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:36:33.222494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:36:33.223105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:36:33.223677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:36:33.223698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:36:33.223703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:36:33.223707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:36:33.223820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:36:33.224505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:36:33.225087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:36:33.225811 140534394648384 saver.py:1284] Restoring parameters from /opt/tf_issue_32052/data/east_net/model.ckpt-20
I0830 20:36:36.581008 140534394648384 session_manager.py:500] Running local_init_op.
I0830 20:36:36.996693 140534394648384 session_manager.py:502] Done running local_init_op.
I0830 20:36:40.482360 140534394648384 evaluation.py:275] Finished evaluation at 2019-08-30-20:36:40
I0830 20:36:40.482950 140534394648384 estimator.py:2039] Saving dict for global step 20: global_step = 20, loss = 1.9114783
I0830 20:36:40.483746 140534394648384 estimator.py:2099] Saving 'checkpoint_path' summary for global step 20: /opt/tf_issue_32052/data/east_net/model.ckpt-20
 67%|██████▋   | 2/3 [17:34<08:47, 527.14s/it]E0830 20:37:30.511528 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch[0m
I0830 20:37:30.512166 140534394648384 print_helper.py:59] [92m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[0m
W0830 20:37:30.512454 140534394648384 print_helper.py:77] [93mMemory used is 13731.70703125[0m
I0830 20:37:30.512731 140534394648384 print_helper.py:59] [92m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<[0m
E0830 20:37:30.513275 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Training[0m
W0830 20:37:30.940150 140534394648384 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fd022147e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 139>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
Line #    Mem usage    Increment   Line Contents
================================================
   161  11068.5 MiB  11068.5 MiB   @profile
   162                             def _get_dataset(data_path):
   163                                 """
   164                                 Reads TFRecords, decode and batches them
   165                                 :return: dataset
   166                                 """
   167  11068.5 MiB      0.0 MiB       _num_cores = 4
   168  11068.5 MiB      0.0 MiB       _batch_size = BATCH_SIZE
   169                             
   170  11068.5 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   171  11068.5 MiB      0.0 MiB       path = path.replace("//", "/")
   172  11068.5 MiB      0.0 MiB       files = tf.data.Dataset.list_files(path)
   173                                 # files = glob.glob(pathname=path)
   174                             
   175                                 # TF dataset APIs
   176  11068.5 MiB      0.0 MiB       dataset = files.interleave(
   177  11068.5 MiB      0.0 MiB           tf.data.TFRecordDataset,
   178  11068.5 MiB      0.0 MiB           cycle_length=_num_cores,
   179  11068.5 MiB      0.0 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   180                             
   181                                 # dataset = tf.data.TFRecordDataset(files, num_parallel_reads=_num_cores)
   182                                 # dataset = dataset.shuffle(_batch_size*10, 42)
   183                                 # Map the generator output as features as a dict and label
   184                             
   185  11068.5 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   186  11068.5 MiB      0.0 MiB         dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   187                                 else:
   188                                   dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   189                             
   190  11068.5 MiB      0.0 MiB       dataset = dataset.batch(batch_size=_batch_size, drop_remainder=False)
   191  11068.5 MiB      0.0 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   192  11068.5 MiB      0.0 MiB       iterator = dataset.make_one_shot_iterator()
   193  11068.5 MiB      0.0 MiB       batch_feats, batch_label = iterator.get_next()
   194  11068.5 MiB      0.0 MiB       return batch_feats, batch_label


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    97  11068.5 MiB  11068.5 MiB   @profile
    98                             def evaluate(estimator, steps=None, checkpoint_path=None):
    99  11068.5 MiB      0.0 MiB       eval_spec = _get_eval_spec(steps=steps)
   100  11068.5 MiB      0.0 MiB       estimator.evaluate(
   101  11068.5 MiB      0.0 MiB           input_fn=eval_spec.input_fn,
   102  11068.5 MiB      0.0 MiB           steps=eval_spec.steps,
   103  11068.5 MiB      0.0 MiB           hooks=eval_spec.hooks,
   104  13731.5 MiB   2663.0 MiB           checkpoint_path=checkpoint_path)


objgraph growth list after iteration 1
tuple                              4095392  +2032001
list                               1342362   +655165
dict                                664975   +307053
set                                 136079    +66682
Tensor                              120108    +60054
Operation                           118350    +59175
_InputList                          118350    +59175
ScopedTFFunction                    117204    +58602
TF_Output                           117752    +57910
_DefinedFunction                    114060    +57030
TraceableObject                      90852    +45426
TensorShape                          95331    +38680
Dimension                            82008    +34359
TraceableStack                       14288     +7144
OrderedDict                          11291     +5568
builtin_function_or_method           16758     +5360
weakref                              20588     +4259
ResourceVariable                      4154     +2077
Condition                             3614     +1786
deque                                 3598     +1786
_local                                3583     +1786
ObjectIdentityWeakSet                 3572     +1786
GroupLock                             3572     +1786
ObjectIdentitySet                     3572     +1786
ScopedTFGraph                         3572     +1786
_WeakObjectIdentityWrapper            3554     +1777
_EagerDefinedFunction                 3144     +1572
CondBranchFuncGraph                   2708     +1354
cell                                 15163      +310
FuncGraph                              436      +218
_CondGradFuncGraph                     424      +212
_ObjectIdentityWrapper                 276      +138
function                             63517       +54
TensorSpec                              54       +26
_VariantTracker                         48       +24
TrackableReference                      48       +24
CapturableResourceDeleter               48       +24
weakproxy                               48       +24
DatasetV1Adapter                        24       +12
StructuredFunctionWrapper                8        +4
ConcreteFunction                         8        +4
ConcreteFunctionGarbageCollector         8        +4
_DelayedRewriteGradientFunctions         8        +4
_FirstOrderTapeGradientFunctions         8        +4
_HigherOrderTapeGradientFunctions        8        +4
defaultdict                              9        +2
Graph                                    4        +2
_VariableScopeStore                      4        +2
_VariableStore                           4        +2
Saver                                    4        +2







Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    70  13731.7 MiB  13731.7 MiB   @profile
    71                             def _get_train_spec(max_steps=None):
    72                                 # Estimators expect an input_fn to take no arguments.
    73                                 # To work around this restriction, we use lambda to capture the arguments and provide the expected interface.
    74  13731.7 MiB      0.0 MiB       return tf.estimator.TrainSpec(
    75  13731.7 MiB      0.0 MiB           input_fn=lambda: _get_dataset(data_path=TRAIN_DATA),
    76  13731.7 MiB      0.0 MiB           max_steps=max_steps,
    77  13731.7 MiB      0.0 MiB           hooks=None)


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   161  13731.7 MiB  13731.7 MiB   @profile
   162                             def _get_dataset(data_path):
   163                                 """
   164                                 Reads TFRecords, decode and batches them
   165                                 :return: dataset
   166                                 """
   167  13731.7 MiB      0.0 MiB       _num_cores = 4
   168  13731.7 MiB      0.0 MiB       _batch_size = BATCH_SIZE
   169                             
   170  13731.7 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   171  13731.7 MiB      0.0 MiB       path = path.replace("//", "/")
   172  13731.7 MiB      0.0 MiB       files = tf.data.Dataset.list_files(path)
   173                                 # files = glob.glob(pathname=path)
   174                             
   175                                 # TF dataset APIs
   176  13731.7 MiB      0.0 MiB       dataset = files.interleave(
   177  13731.7 MiB      0.0 MiB           tf.data.TFRecordDataset,
   178  13731.7 MiB      0.0 MiB           cycle_length=_num_cores,
   179  13731.7 MiB      0.0 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   180                             
   181                                 # dataset = tf.data.TFRecordDataset(files, num_parallel_reads=_num_cores)
   182                                 # dataset = dataset.shuffle(_batch_size*10, 42)
I0830 20:37:31.166805 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:37:31.167475 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:1", shape=(None, 512, 512, 3), dtype=float32, device=/device:CPU:0)[0m
W0830 20:37:31.205043 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:37:31.205750 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, 512, 512, 3), dtype=float32)[0m
W0830 20:37:31.218596 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, 518, 518, 3), dtype=float32)[0m
W0830 20:37:31.323737 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:37:31.736078 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:37:31.744595 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:37:31.757373 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, 258, 258, 64), dtype=float32)[0m
W0830 20:37:31.768095 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
W0830 20:37:31.768536 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:37:31.768932 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:37:31.769322 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:37:31.769790 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:31.874709 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:32.290807 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:32.299550 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:32.407080 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:32.819050 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:32.827539 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:32.932373 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:33.341966 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:33.447090 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:33.851541 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:33.861234 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:33.869731 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:37:33.870267 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:37:33.870672 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:33.871158 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:33.975956 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:34.390992 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:34.399711 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:34.506931 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:34.924900 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:34.933630 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:35.041009 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:35.459725 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:35.470165 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:35.479268 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:37:35.479822 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:37:35.480240 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:35.480739 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:35.591207 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:36.015764 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:36.024517 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:36.133866 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:36.560004 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:36.568778 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:37:36.676659 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:37.094718 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:37.105930 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:37.114671 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:37:37.115199 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:37:37.115603 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:37:37.116003 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:37:37.116482 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:37:37.225219 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:37.648499 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:37.657273 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:37.765076 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:38.183446 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:38.191950 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:38.296510 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:38.701381 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:38.807264 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:39.214481 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:39.224120 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:39.232391 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:39.232904 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:39.233293 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:39.233748 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:39.338359 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:39.746669 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:39.754999 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:39.859475 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:40.264442 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:40.273090 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:40.380730 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:40.785949 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:40.795520 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:40.803931 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:40.804452 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:40.804855 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:40.805323 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:40.910560 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:41.318850 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:41.327182 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:41.431857 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:41.837634 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:41.846298 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:41.951839 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:42.368079 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:42.378157 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:42.386858 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:42.387387 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:42.387798 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:42.388280 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:42.496893 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:42.919422 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:42.928208 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:43.036283 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:43.459648 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:43.468452 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:37:43.576326 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:43.997022 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:44.007001 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:44.015722 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:44.016258 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:37:44.016665 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:37:44.017073 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:37:44.017553 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:37:44.127519 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:44.544759 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:44.553278 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:44.661223 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:45.080613 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:45.089357 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:45.205598 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:45.659282 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:45.776344 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:46.231920 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:46.241937 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:46.250391 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:46.250912 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:46.251310 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:46.251780 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:46.359865 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:46.772303 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:46.780679 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:46.886008 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:47.291646 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:47.300172 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:47.413717 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:47.856609 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:47.866341 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:47.875069 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:47.875619 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:47.876033 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:47.876521 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:47.984373 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:48.401930 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:48.411390 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:48.530963 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:48.961038 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:48.969628 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:49.083554 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:49.531134 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:49.541035 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:49.549543 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:49.550065 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:49.550465 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:49.550935 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:49.658398 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:50.071273 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:50.079857 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:50.187677 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:50.609837 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:50.618664 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:50.736169 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:51.197887 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:51.207966 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:51.216750 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:51.217280 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:51.217685 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:51.218165 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:51.328678 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:51.748699 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:51.757306 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:51.865514 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:52.284059 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:52.292692 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:52.409110 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:52.867513 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:52.877596 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:52.886489 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:52.887027 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:52.887436 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:52.887917 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:52.996508 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:53.412616 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:53.421455 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:53.530726 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:53.951366 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:53.959989 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:37:54.077971 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:54.519582 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:54.529158 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:54.537459 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:54.537963 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:37:54.538357 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:37:54.538738 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:37:54.539192 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:37:54.645109 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:55.051114 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:55.059548 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:55.165242 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:55.573346 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:55.582018 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:55.697211 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:56.139222 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:56.253676 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:56.693127 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:56.702904 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:56.711253 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:37:56.711758 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:37:56.712146 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:56.712603 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:56.819458 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:57.232310 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:57.240930 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:57.346110 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:57.754425 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:57.762867 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:57.877491 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:58.321615 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:58.331670 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:58.340482 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:37:58.341027 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:37:58.341438 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:37:58.341919 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:58.450585 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:58.872627 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:58.881479 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:58.989716 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:59.406417 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:59.415248 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:37:59.532021 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:59.981764 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:37:59.991557 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:38:00.000253 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:38:00.000805 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:38:00.001322 140534394648384 east_model.py:252] Shape of f_0 : (None, 16, 16, 2048)
I0830 20:38:00.001851 140534394648384 east_model.py:252] Shape of f_1 : (None, 32, 32, 1024)
I0830 20:38:00.002392 140534394648384 east_model.py:252] Shape of f_2 : (None, 64, 64, 512)
I0830 20:38:00.002868 140534394648384 east_model.py:252] Shape of f_3 : (None, 128, 128, 256)
I0830 20:38:00.066389 140534394648384 east_model.py:271] Shape of h_0 : (None, 16, 16, 2048), g_0 : (None, None, None, 2048)
I0830 20:38:00.365150 140534394648384 east_model.py:271] Shape of h_1 : (None, 32, 32, 128), g_1 : (None, None, None, 128)
I0830 20:38:00.659184 140534394648384 east_model.py:271] Shape of h_2 : (None, 64, 64, 64), g_2 : (None, None, None, 64)
I0830 20:38:01.001675 140534394648384 east_model.py:271] Shape of h_3 : (None, 128, 128, 32), g_3 : (None, 128, 128, 32)
E0830 20:38:01.352231 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:0", shape=(None, 128, 128, 5), dtype=float32, device=/device:CPU:0)[0m
E0830 20:38:01.352900 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:2", shape=(None, 128, 128, 1), dtype=float32, device=/device:CPU:0)[0m
E0830 20:38:01.353579 140534394648384 print_helper.py:68] [31mTensor("conv2d_7/Sigmoid:0", shape=(None, 128, 128, 1), dtype=float32)[0m
E0830 20:38:01.354243 140534394648384 print_helper.py:68] [31mTensor("concat_4:0", shape=(None, 128, 128, 5), dtype=float32)[0m
E0830 20:38:01.592463 140534394648384 print_helper.py:68] [31mTensor("add_28:0", shape=(), dtype=float32)[0m
I0830 20:39:56.434789 140534394648384 estimator.py:1147] Done calling model_fn.
I0830 20:39:56.442538 140534394648384 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
I0830 20:40:13.672559 140534394648384 monitored_session.py:240] Graph was finalized.
2019-08-30 20:40:13.673768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:40:13.674462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:40:13.674505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:40:13.674520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:40:13.674532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:40:13.674544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:40:13.674556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:40:13.674568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:40:13.674582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:40:13.674639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:40:13.675299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:40:13.675884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:40:13.675905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:40:13.675910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:40:13.675914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:40:13.676031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:40:13.676657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:40:13.677266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:40:13.680316 140534394648384 saver.py:1284] Restoring parameters from /opt/tf_issue_32052/data/east_net/model.ckpt-20
I0830 20:40:17.034537 140534394648384 session_manager.py:500] Running local_init_op.
I0830 20:40:17.443079 140534394648384 session_manager.py:502] Done running local_init_op.
I0830 20:41:24.990122 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 20 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:41:39.874109 140534394648384 basic_session_run_hooks.py:262] loss = 1.9114413, step = 20
I0830 20:41:48.537719 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 0.23082
I0830 20:41:48.539387 140534394648384 basic_session_run_hooks.py:260] loss = 1.9064435, step = 22 (8.665 sec)
I0830 20:41:49.315129 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 2.57265
I0830 20:41:49.316779 140534394648384 basic_session_run_hooks.py:260] loss = 1.9265698, step = 24 (0.777 sec)
I0830 20:41:49.709640 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 26 into /opt/tf_issue_32052/data/east_net/model.ckpt.
W0830 20:41:49.968538 140534394648384 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I0830 20:41:52.785617 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 0.576288
I0830 20:41:52.787550 140534394648384 basic_session_run_hooks.py:260] loss = 1.9007292, step = 26 (3.471 sec)
I0830 20:41:53.568085 140534394648384 basic_session_run_hooks.py:692] global_step/sec: 2.55602
I0830 20:41:53.569677 140534394648384 basic_session_run_hooks.py:260] loss = 1.9163194, step = 28 (0.782 sec)
I0830 20:41:53.991166 140534394648384 basic_session_run_hooks.py:606] Saving checkpoints for 30 into /opt/tf_issue_32052/data/east_net/model.ckpt.
I0830 20:41:57.475525 140534394648384 estimator.py:368] Loss for final step: 1.92085.
E0830 20:41:57.478095 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Evaluating[0m
W0830 20:41:57.875083 140534394648384 ag_logging.py:146] Entity <bound method CodeMap.items of {<code object east_features_decode at 0x7fd022147e40, file "/opt/tf_issue_32052/dummy_datasets.py", line 139>: {}}> appears to be a generator function. It will not be converted by AutoGraph.
I0830 20:41:58.108213 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:41:58.108911 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:1", shape=(None, 512, 512, 3), dtype=float32, device=/device:CPU:0)[0m
W0830 20:41:58.153204 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:41:58.153941 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, 512, 512, 3), dtype=float32)[0m
W0830 20:41:58.167894 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, 518, 518, 3), dtype=float32)[0m
W0830 20:41:58.277905 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:41:58.706236 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:41:58.714818 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, 256, 256, 64), dtype=float32)[0m
W0830 20:41:58.728897 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, 258, 258, 64), dtype=float32)[0m
W0830 20:41:58.740779 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
W0830 20:41:58.741236 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:41:58.741645 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:41:58.742051 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:41:58.742545 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:58.851032 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:59.270685 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:59.279338 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:59.387765 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:59.809710 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:59.819682 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:41:59.928122 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:00.347706 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:00.457858 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:00.877225 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:00.887420 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:00.896986 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:42:00.897537 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:42:00.897957 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:00.898445 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:01.006768 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:01.427184 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:01.435994 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:01.546369 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:01.964794 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:01.973544 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:02.081887 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:02.502272 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:02.512203 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:02.521808 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:42:02.522360 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:42:02.522765 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:02.523245 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:02.631153 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:03.052726 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:03.061433 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:03.172808 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:03.595725 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:03.604476 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, 128, 128, 64), dtype=float32)[0m
I0830 20:42:03.712547 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:04.131676 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:04.141726 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:04.151434 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:42:04.151994 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
W0830 20:42:04.152407 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:42:04.152821 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:42:04.153311 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, 128, 128, 256), dtype=float32)[0m
I0830 20:42:04.261184 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:04.683843 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:04.692450 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:04.801248 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:05.221199 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:05.229943 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:05.338923 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:05.761240 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:05.870517 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:06.291439 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:06.301489 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:06.311034 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:06.311594 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:06.312034 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:06.312525 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:06.420421 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:06.849242 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:06.857826 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:06.967405 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:07.387274 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:07.395973 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:07.507819 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:07.928712 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:07.938642 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:07.948126 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:07.948741 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:07.949170 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:07.949678 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:08.058534 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:08.483967 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:08.492628 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:08.601611 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:09.022971 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:09.031795 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:09.140316 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:09.562711 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:09.572710 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:09.582276 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:09.582822 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:09.583240 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:09.583732 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:09.691657 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:10.113656 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:10.122359 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:10.230772 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:10.655816 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:10.664605 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, 64, 64, 128), dtype=float32)[0m
I0830 20:42:10.773872 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:11.195752 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:11.205769 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:11.215431 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:11.215992 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
W0830 20:42:11.216421 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:42:11.216849 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:42:11.217352 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, 64, 64, 512), dtype=float32)[0m
I0830 20:42:11.326313 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:11.750821 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:11.759603 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:11.868960 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:12.292538 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:12.301322 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:12.419198 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:12.877650 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:12.995390 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:13.454775 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:13.466520 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:13.475293 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:13.475826 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:13.476238 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:13.476724 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:13.585220 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:14.006263 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:14.015006 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:14.123067 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:14.547035 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:14.555771 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:14.672317 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:15.402155 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:15.419223 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:15.433913 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:15.434852 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:15.435545 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:15.436360 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:15.622172 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:16.334836 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:16.350921 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:16.545116 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:17.255331 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:17.271440 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:17.469850 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:18.251150 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:18.269302 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:18.288151 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:18.289866 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:18.291234 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:18.292869 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:18.477407 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:19.037438 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:19.047234 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:19.169704 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:19.642102 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:19.651884 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:19.784897 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:20.296263 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:20.307505 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:20.317308 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:20.317906 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:20.318364 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:20.318903 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:20.439657 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:20.915464 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:20.925271 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:21.046256 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:21.519249 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:21.529090 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:21.659455 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:22.170594 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:22.181771 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:22.191497 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:22.192089 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:22.192550 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:22.193097 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:22.314009 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:22.781464 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:22.790226 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:22.898523 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:23.325158 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:23.333895 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, 32, 32, 256), dtype=float32)[0m
I0830 20:42:23.451293 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:23.908662 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:23.918689 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:23.927387 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:23.927929 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
W0830 20:42:23.928335 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:42:23.928744 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:42:23.929226 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, 32, 32, 1024), dtype=float32)[0m
I0830 20:42:24.037093 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:24.458976 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:24.467893 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:24.576095 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:25.037081 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:25.047180 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:25.186062 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:25.744010 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:25.888960 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:26.452928 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:26.465659 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:26.476500 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:42:26.477145 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:42:26.477652 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:26.478249 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:26.614270 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:27.138629 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:27.149398 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:27.285037 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:27.818120 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:27.828870 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:27.977270 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:28.549465 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:28.561921 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:28.572597 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:42:28.573242 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:42:28.573744 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:42:28.574339 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:28.711720 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:29.242120 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:29.252890 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:29.387697 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:29.909140 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:29.919944 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, 16, 16, 512), dtype=float32)[0m
I0830 20:42:30.067667 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:30.635815 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:30.648225 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:30.658952 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
W0830 20:42:30.659593 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, 16, 16, 2048), dtype=float32)[0m
I0830 20:42:30.660165 140534394648384 east_model.py:252] Shape of f_0 : (None, 16, 16, 2048)
I0830 20:42:30.660719 140534394648384 east_model.py:252] Shape of f_1 : (None, 32, 32, 1024)
I0830 20:42:30.661262 140534394648384 east_model.py:252] Shape of f_2 : (None, 64, 64, 512)
I0830 20:42:30.661802 140534394648384 east_model.py:252] Shape of f_3 : (None, 128, 128, 256)
I0830 20:42:30.739993 140534394648384 east_model.py:271] Shape of h_0 : (None, 16, 16, 2048), g_0 : (None, None, None, 2048)
I0830 20:42:31.098376 140534394648384 east_model.py:271] Shape of h_1 : (None, 32, 32, 128), g_1 : (None, None, None, 128)
I0830 20:42:31.442596 140534394648384 east_model.py:271] Shape of h_2 : (None, 64, 64, 64), g_2 : (None, None, None, 64)
I0830 20:42:31.855813 140534394648384 east_model.py:271] Shape of h_3 : (None, 128, 128, 32), g_3 : (None, 128, 128, 32)
E0830 20:42:32.299978 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:0", shape=(None, 128, 128, 5), dtype=float32, device=/device:CPU:0)[0m
E0830 20:42:32.300788 140534394648384 print_helper.py:68] [31mTensor("IteratorGetNext:2", shape=(None, 128, 128, 1), dtype=float32, device=/device:CPU:0)[0m
E0830 20:42:32.301617 140534394648384 print_helper.py:68] [31mTensor("conv2d_7/Sigmoid:0", shape=(None, 128, 128, 1), dtype=float32)[0m
E0830 20:42:32.302429 140534394648384 print_helper.py:68] [31mTensor("concat_4:0", shape=(None, 128, 128, 5), dtype=float32)[0m
E0830 20:42:32.603867 140534394648384 print_helper.py:68] [31mTensor("add_28:0", shape=(), dtype=float32)[0m
I0830 20:44:33.374329 140534394648384 estimator.py:1147] Done calling model_fn.
I0830 20:44:33.551839 140534394648384 evaluation.py:255] Starting evaluation at 2019-08-30T20:44:33Z
I0830 20:44:51.484946 140534394648384 monitored_session.py:240] Graph was finalized.
2019-08-30 20:44:51.486041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:44:51.486681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:44:51.486721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:44:51.486736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:44:51.486753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:44:51.486767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:44:51.486778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:44:51.486790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:44:51.486801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:44:51.486856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:44:51.487472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:44:51.488096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:44:51.488117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:44:51.488122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:44:51.488126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:44:51.488242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:44:51.488871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:44:51.489465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:44:51.490201 140534394648384 saver.py:1284] Restoring parameters from /opt/tf_issue_32052/data/east_net/model.ckpt-30
I0830 20:44:54.824433 140534394648384 session_manager.py:500] Running local_init_op.
I0830 20:44:55.234810 140534394648384 session_manager.py:502] Done running local_init_op.
I0830 20:44:58.728829 140534394648384 evaluation.py:275] Finished evaluation at 2019-08-30-20:44:58
I0830 20:44:58.729355 140534394648384 estimator.py:2039] Saving dict for global step 30: global_step = 30, loss = 1.9114794
I0830 20:44:58.730083 140534394648384 estimator.py:2099] Saving 'checkpoint_path' summary for global step 30: /opt/tf_issue_32052/data/east_net/model.ckpt-30
100%|██████████| 3/3 [26:13<00:00, 524.73s/it]
E0830 20:46:33.654293 140534394648384 print_helper.py:68] [31m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch[0m
I0830 20:46:33.661720 140534394648384 tf_memory_test.py:122] Saving model to =======> /opt/tf_issue_32052/data/east_net/export
   183                                 # Map the generator output as features as a dict and label
   184                             
   185  13731.7 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   186  13731.7 MiB      0.0 MiB         dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   187                                 else:
   188                                   dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   189                             
   190  13731.7 MiB      0.0 MiB       dataset = dataset.batch(batch_size=_batch_size, drop_remainder=False)
   191  13732.0 MiB      0.3 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   192  13732.1 MiB      0.2 MiB       iterator = dataset.make_one_shot_iterator()
   193  13732.1 MiB      0.0 MiB       batch_feats, batch_label = iterator.get_next()
   194  13732.1 MiB      0.0 MiB       return batch_feats, batch_label


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    88  13731.7 MiB  13731.7 MiB   @profile
    89                             def train(estimator, max_steps=None):
    90  13731.7 MiB      0.0 MiB       train_spec = _get_train_spec(max_steps=max_steps)
    91  13731.7 MiB      0.0 MiB       estimator.train(
    92  13731.7 MiB      0.0 MiB           input_fn=train_spec.input_fn,
    93  13731.7 MiB      0.0 MiB           hooks=train_spec.hooks,
    94  16514.7 MiB   2783.0 MiB           max_steps=train_spec.max_steps)


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    80  16514.7 MiB  16514.7 MiB   @profile
    81                             def _get_eval_spec(steps):
    82  16514.7 MiB      0.0 MiB       return tf.estimator.EvalSpec(
    83  16514.7 MiB      0.0 MiB           input_fn=lambda: _get_dataset(data_path=VAL_DATA),
    84  16514.7 MiB      0.0 MiB           steps=steps,
    85  16514.7 MiB      0.0 MiB           hooks=None)


Filename: /opt/tf_issue_32052/dummy_datasets.py

Line #    Mem usage    Increment   Line Contents
================================================
   161  16514.7 MiB  16514.7 MiB   @profile
   162                             def _get_dataset(data_path):
   163                                 """
   164                                 Reads TFRecords, decode and batches them
   165                                 :return: dataset
   166                                 """
   167  16514.7 MiB      0.0 MiB       _num_cores = 4
   168  16514.7 MiB      0.0 MiB       _batch_size = BATCH_SIZE
   169                             
   170  16514.7 MiB      0.0 MiB       path = os.path.join(data_path, "*.tfrecords")
   171  16514.7 MiB      0.0 MiB       path = path.replace("//", "/")
   172  16514.7 MiB      0.0 MiB       files = tf.data.Dataset.list_files(path)
   173                                 # files = glob.glob(pathname=path)
   174                             
   175                                 # TF dataset APIs
   176  16514.7 MiB      0.0 MiB       dataset = files.interleave(
   177  16514.7 MiB      0.0 MiB           tf.data.TFRecordDataset,
   178  16514.7 MiB      0.0 MiB           cycle_length=_num_cores,
   179  16514.7 MiB      0.0 MiB           num_parallel_calls=tf.data.experimental.AUTOTUNE)
   180                             
   181                                 # dataset = tf.data.TFRecordDataset(files, num_parallel_reads=_num_cores)
   182                                 # dataset = dataset.shuffle(_batch_size*10, 42)
   183                                 # Map the generator output as features as a dict and label
   184                             
   185  16514.7 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   186  16514.7 MiB      0.0 MiB         dataset = dataset.map(map_func=east_features_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   187                                 else:
   188                                   dataset = dataset.map(map_func=numpy_array_decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)
   189                             
   190  16514.7 MiB      0.0 MiB       dataset = dataset.batch(batch_size=_batch_size, drop_remainder=False)
   191  16514.7 MiB      0.0 MiB       dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
   192  16514.7 MiB      0.0 MiB       iterator = dataset.make_one_shot_iterator()
   193  16514.7 MiB      0.0 MiB       batch_feats, batch_label = iterator.get_next()
   194  16514.7 MiB      0.0 MiB       return batch_feats, batch_label


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
    97  16514.7 MiB  16514.7 MiB   @profile
    98                             def evaluate(estimator, steps=None, checkpoint_path=None):
    99  16514.7 MiB      0.0 MiB       eval_spec = _get_eval_spec(steps=steps)
   100  16514.7 MiB      0.0 MiB       estimator.evaluate(
   101  16514.7 MiB      0.0 MiB           input_fn=eval_spec.input_fn,
   102  16514.7 MiB      0.0 MiB           steps=eval_spec.steps,
   103  16514.7 MiB      0.0 MiB           hooks=eval_spec.hooks,
   104  18909.6 MiB   2394.8 MiB           checkpoint_path=checkpoint_path)


objgraph growth list after iteration 2
tuple                              6127393  +2032001
list                               1997527   +655165
dict                                972028   +307053
set                                 202761    +66682
Tensor                              180162    +60054
Operation                           177525    +59175
_InputList                          177525    +59175
ScopedTFFunction                    175806    +58602
TF_Output                           175662    +57910
_DefinedFunction                    171090    +57030
TraceableObject                     136278    +45426
TensorShape                         134011    +38680
Dimension                           116367    +34359
TraceableStack                       21432     +7144
OrderedDict                          16859     +5568
builtin_function_or_method           22118     +5360
weakref                              24847     +4259
ResourceVariable                      6231     +2077
Condition                             5400     +1786
deque                                 5384     +1786
_local                                5369     +1786
ObjectIdentityWeakSet                 5358     +1786
GroupLock                             5358     +1786
ObjectIdentitySet                     5358     +1786
ScopedTFGraph                         5358     +1786
_WeakObjectIdentityWrapper            5331     +1777
_EagerDefinedFunction                 4716     +1572
CondBranchFuncGraph                   4062     +1354
cell                                 15473      +310
FuncGraph                              654      +218
_CondGradFuncGraph                     636      +212
_ObjectIdentityWrapper                 414      +138
function                             63571       +54
TensorSpec                              80       +26
_VariantTracker                         72       +24
TrackableReference                      72       +24
CapturableResourceDeleter               72       +24
weakproxy                               72       +24
DatasetV1Adapter                        36       +12
StructuredFunctionWrapper               12        +4
ConcreteFunction                        12        +4
ConcreteFunctionGarbageCollector        12        +4
_DelayedRewriteGradientFunctions        12        +4
_FirstOrderTapeGradientFunctions        12        +4
_HigherOrderTapeGradientFunctions       12        +4
defaultdict                             11        +2
Graph                                    6        +2
_VariableScopeStore                      6        +2
_VariableStore                           6        +2
Saver                                    6        +2
Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
I0830 20:46:33.717276 140534394648384 estimator.py:1145] Calling model_fn.
E0830 20:46:33.718034 140534394648384 print_helper.py:68] [31mTensor("Placeholder:0", shape=(None, None, None, 3), dtype=float32)[0m
W0830 20:46:33.755700 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Model Definition Started: [0m
W0830 20:46:33.756398 140534394648384 print_helper.py:77] [93mTensor("concat:0", shape=(None, None, None, 3), dtype=float32)[0m
W0830 20:46:33.769443 140534394648384 print_helper.py:77] [93mTensor("conv1_pad/Pad:0", shape=(None, None, None, 3), dtype=float32)[0m
W0830 20:46:33.874013 140534394648384 print_helper.py:77] [93mTensor("conv1/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
W0830 20:46:34.286709 140534394648384 print_helper.py:77] [93mTensor("bn_conv1/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
W0830 20:46:34.295024 140534394648384 print_helper.py:77] [93mTensor("activation/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
W0830 20:46:34.307986 140534394648384 print_helper.py:77] [93mTensor("pool1_pad/Pad:0", shape=(None, None, None, 64), dtype=float32)[0m
W0830 20:46:34.318765 140534394648384 print_helper.py:77] [93mTensor("max_pooling2d/MaxPool:0", shape=(None, None, None, 64), dtype=float32)[0m
W0830 20:46:34.319245 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>> Resnet Definition Started: [0m
W0830 20:46:34.319629 140534394648384 print_helper.py:77] [93m>>>>> pool2[0m
W0830 20:46:34.320012 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:46:34.320474 140534394648384 print_helper.py:59] [92mTensor("max_pooling2d/MaxPool:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:34.427413 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2a/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:34.853990 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2a/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:34.862345 140534394648384 print_helper.py:59] [92mTensor("activation_1/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:34.967667 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2b/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:35.385120 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2b/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:35.393545 140534394648384 print_helper.py:59] [92mTensor("activation_2/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:35.497587 140534394648384 print_helper.py:59] [92mTensor("res2a_branch2c/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:35.899285 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch2c/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:36.004523 140534394648384 print_helper.py:59] [92mTensor("res2a_branch1/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:36.406172 140534394648384 print_helper.py:59] [92mTensor("bn2a_branch1/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:36.415948 140534394648384 print_helper.py:59] [92mTensor("add/add:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:36.426205 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
W0830 20:46:36.426715 140534394648384 print_helper.py:77] [93mTensor("activation_3/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
W0830 20:46:36.427094 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:36.427544 140534394648384 print_helper.py:59] [92mTensor("activation_3/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:36.532938 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2a/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:36.936117 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2a/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:36.944660 140534394648384 print_helper.py:59] [92mTensor("activation_4/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:37.049727 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2b/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:37.455892 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2b/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:37.464389 140534394648384 print_helper.py:59] [92mTensor("activation_5/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:37.571856 140534394648384 print_helper.py:59] [92mTensor("res2b_branch2c/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:37.976512 140534394648384 print_helper.py:59] [92mTensor("bn2b_branch2c/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:37.986320 140534394648384 print_helper.py:59] [92mTensor("add_1/add:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:37.996371 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
W0830 20:46:37.996881 140534394648384 print_helper.py:77] [93mTensor("activation_6/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
W0830 20:46:37.997267 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:37.997722 140534394648384 print_helper.py:59] [92mTensor("activation_6/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:38.104401 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2a/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:38.510740 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2a/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:38.519055 140534394648384 print_helper.py:59] [92mTensor("activation_7/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:38.623757 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2b/BiasAdd:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:39.049052 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2b/cond/Identity:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:39.057539 140534394648384 print_helper.py:59] [92mTensor("activation_8/Relu:0", shape=(None, None, None, 64), dtype=float32)[0m
I0830 20:46:39.161590 140534394648384 print_helper.py:59] [92mTensor("res2c_branch2c/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:39.562839 140534394648384 print_helper.py:59] [92mTensor("bn2c_branch2c/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:39.572495 140534394648384 print_helper.py:59] [92mTensor("add_2/add:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:39.581069 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
W0830 20:46:39.581602 140534394648384 print_helper.py:77] [93mTensor("activation_9/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
W0830 20:46:39.581980 140534394648384 print_helper.py:77] [93m>>>>> pool3[0m
W0830 20:46:39.582426 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:46:39.582886 140534394648384 print_helper.py:59] [92mTensor("activation_9/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:39.687247 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2a/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:40.088521 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2a/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:40.096850 140534394648384 print_helper.py:59] [92mTensor("activation_10/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:40.200607 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2b/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:40.604279 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2b/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:40.612623 140534394648384 print_helper.py:59] [92mTensor("activation_11/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:40.716216 140534394648384 print_helper.py:59] [92mTensor("res3a_branch2c/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:41.120496 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch2c/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:41.224777 140534394648384 print_helper.py:59] [92mTensor("res3a_branch1/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:41.628046 140534394648384 print_helper.py:59] [92mTensor("bn3a_branch1/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:41.637767 140534394648384 print_helper.py:59] [92mTensor("add_3/add:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:41.645925 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:41.646421 140534394648384 print_helper.py:77] [93mTensor("activation_12/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:41.646810 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:41.647264 140534394648384 print_helper.py:59] [92mTensor("activation_12/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:41.751096 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2a/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:42.154676 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2a/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:42.163048 140534394648384 print_helper.py:59] [92mTensor("activation_13/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:42.266557 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2b/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:42.671196 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2b/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:42.679717 140534394648384 print_helper.py:59] [92mTensor("activation_14/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:42.783097 140534394648384 print_helper.py:59] [92mTensor("res3b_branch2c/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:43.187725 140534394648384 print_helper.py:59] [92mTensor("bn3b_branch2c/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:43.197329 140534394648384 print_helper.py:59] [92mTensor("add_4/add:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:43.205509 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:43.206004 140534394648384 print_helper.py:77] [93mTensor("activation_15/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:43.206390 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:43.206848 140534394648384 print_helper.py:59] [92mTensor("activation_15/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:43.314039 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2a/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:43.717705 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2a/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:43.726066 140534394648384 print_helper.py:59] [92mTensor("activation_16/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:43.831427 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2b/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:44.241572 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2b/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:44.250100 140534394648384 print_helper.py:59] [92mTensor("activation_17/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:44.353704 140534394648384 print_helper.py:59] [92mTensor("res3c_branch2c/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:44.758096 140534394648384 print_helper.py:59] [92mTensor("bn3c_branch2c/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:44.767717 140534394648384 print_helper.py:59] [92mTensor("add_5/add:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:44.776000 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:44.776530 140534394648384 print_helper.py:77] [93mTensor("activation_18/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:44.776945 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:44.777412 140534394648384 print_helper.py:59] [92mTensor("activation_18/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:44.881726 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2a/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:45.289628 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2a/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:45.298141 140534394648384 print_helper.py:59] [92mTensor("activation_19/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:45.402751 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2b/BiasAdd:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:45.811391 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2b/cond/Identity:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:45.820028 140534394648384 print_helper.py:59] [92mTensor("activation_20/Relu:0", shape=(None, None, None, 128), dtype=float32)[0m
I0830 20:46:45.926266 140534394648384 print_helper.py:59] [92mTensor("res3d_branch2c/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:46.337443 140534394648384 print_helper.py:59] [92mTensor("bn3d_branch2c/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:46.347095 140534394648384 print_helper.py:59] [92mTensor("add_6/add:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:46.355521 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:46.356031 140534394648384 print_helper.py:77] [93mTensor("activation_21/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
W0830 20:46:46.356431 140534394648384 print_helper.py:77] [93m>>>>> pool4[0m
W0830 20:46:46.356840 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:46:46.357311 140534394648384 print_helper.py:59] [92mTensor("activation_21/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:46.462136 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2a/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:46.871771 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2a/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:46.880078 140534394648384 print_helper.py:59] [92mTensor("activation_22/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:46.984074 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2b/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:47.392301 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2b/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:47.400820 140534394648384 print_helper.py:59] [92mTensor("activation_23/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:47.514147 140534394648384 print_helper.py:59] [92mTensor("res4a_branch2c/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:47.956941 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch2c/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:48.071155 140534394648384 print_helper.py:59] [92mTensor("res4a_branch1/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:48.516267 140534394648384 print_helper.py:59] [92mTensor("bn4a_branch1/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:48.526533 140534394648384 print_helper.py:59] [92mTensor("add_7/add:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:48.535376 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:48.535924 140534394648384 print_helper.py:77] [93mTensor("activation_24/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:48.536380 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:48.536893 140534394648384 print_helper.py:59] [92mTensor("activation_24/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:48.641828 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2a/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:49.057616 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2a/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:49.066414 140534394648384 print_helper.py:59] [92mTensor("activation_25/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:49.173511 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2b/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:49.580556 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2b/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:49.588874 140534394648384 print_helper.py:59] [92mTensor("activation_26/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:49.700988 140534394648384 print_helper.py:59] [92mTensor("res4b_branch2c/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:50.136824 140534394648384 print_helper.py:59] [92mTensor("bn4b_branch2c/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:50.146382 140534394648384 print_helper.py:59] [92mTensor("add_8/add:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:50.154823 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:50.155369 140534394648384 print_helper.py:77] [93mTensor("activation_27/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:50.155786 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:50.156271 140534394648384 print_helper.py:59] [92mTensor("activation_27/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:50.259999 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2a/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:50.683445 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2a/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:50.692027 140534394648384 print_helper.py:59] [92mTensor("activation_28/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:50.799495 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2b/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:51.212621 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2b/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:51.221074 140534394648384 print_helper.py:59] [92mTensor("activation_29/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:51.335630 140534394648384 print_helper.py:59] [92mTensor("res4c_branch2c/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:51.785365 140534394648384 print_helper.py:59] [92mTensor("bn4c_branch2c/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:51.795403 140534394648384 print_helper.py:59] [92mTensor("add_9/add:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:51.804928 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:51.805462 140534394648384 print_helper.py:77] [93mTensor("activation_30/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:51.805870 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:51.806348 140534394648384 print_helper.py:59] [92mTensor("activation_30/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:51.913245 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2a/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:52.325685 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2a/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:52.334242 140534394648384 print_helper.py:59] [92mTensor("activation_31/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:52.440265 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2b/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:52.850797 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2b/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:52.859261 140534394648384 print_helper.py:59] [92mTensor("activation_32/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:52.973219 140534394648384 print_helper.py:59] [92mTensor("res4d_branch2c/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:53.423212 140534394648384 print_helper.py:59] [92mTensor("bn4d_branch2c/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:53.432975 140534394648384 print_helper.py:59] [92mTensor("add_10/add:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:53.441336 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:53.441860 140534394648384 print_helper.py:77] [93mTensor("activation_33/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:53.442246 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:53.442728 140534394648384 print_helper.py:59] [92mTensor("activation_33/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:53.549266 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2a/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:53.961835 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2a/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:53.970223 140534394648384 print_helper.py:59] [92mTensor("activation_34/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:54.075628 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2b/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:54.486934 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2b/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:54.495409 140534394648384 print_helper.py:59] [92mTensor("activation_35/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:54.609474 140534394648384 print_helper.py:59] [92mTensor("res4e_branch2c/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:55.055861 140534394648384 print_helper.py:59] [92mTensor("bn4e_branch2c/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:55.065870 140534394648384 print_helper.py:59] [92mTensor("add_11/add:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:55.074538 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:55.075072 140534394648384 print_helper.py:77] [93mTensor("activation_36/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:55.075479 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:55.075960 140534394648384 print_helper.py:59] [92mTensor("activation_36/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:55.183801 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2a/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:55.604782 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2a/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:55.613525 140534394648384 print_helper.py:59] [92mTensor("activation_37/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:55.721751 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2b/BiasAdd:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:56.142563 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2b/cond/Identity:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:56.151336 140534394648384 print_helper.py:59] [92mTensor("activation_38/Relu:0", shape=(None, None, None, 256), dtype=float32)[0m
I0830 20:46:56.268669 140534394648384 print_helper.py:59] [92mTensor("res4f_branch2c/BiasAdd:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:56.726543 140534394648384 print_helper.py:59] [92mTensor("bn4f_branch2c/cond/Identity:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:56.736521 140534394648384 print_helper.py:59] [92mTensor("add_12/add:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:56.745251 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:56.745784 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
W0830 20:46:56.746194 140534394648384 print_helper.py:77] [93m>>>>> pool5[0m
W0830 20:46:56.746596 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> conv block[0m
I0830 20:46:56.747075 140534394648384 print_helper.py:59] [92mTensor("activation_39/Relu:0", shape=(None, None, None, 1024), dtype=float32)[0m
I0830 20:46:56.855197 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2a/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:57.278451 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2a/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:57.287189 140534394648384 print_helper.py:59] [92mTensor("activation_40/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:57.395225 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2b/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:57.814845 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2b/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:57.823560 140534394648384 print_helper.py:59] [92mTensor("activation_41/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:57.940068 140534394648384 print_helper.py:59] [92mTensor("res5a_branch2c/BiasAdd:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:46:58.398019 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch2c/cond/Identity:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:46:58.514137 140534394648384 print_helper.py:59] [92mTensor("res5a_branch1/BiasAdd:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:46:58.968120 140534394648384 print_helper.py:59] [92mTensor("bn5a_branch1/cond/Identity:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:46:58.978268 140534394648384 print_helper.py:59] [92mTensor("add_13/add:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:46:58.986756 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
W0830 20:46:58.987276 140534394648384 print_helper.py:77] [93mTensor("activation_42/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
W0830 20:46:58.987685 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:46:58.988165 140534394648384 print_helper.py:59] [92mTensor("activation_42/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:46:59.090794 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2a/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:59.495963 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2a/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:59.504360 140534394648384 print_helper.py:59] [92mTensor("activation_43/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:46:59.609882 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2b/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:00.017240 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2b/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:00.025866 140534394648384 print_helper.py:59] [92mTensor("activation_44/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:00.138585 140534394648384 print_helper.py:59] [92mTensor("res5b_branch2c/BiasAdd:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:00.577799 140534394648384 print_helper.py:59] [92mTensor("bn5b_branch2c/cond/Identity:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:00.587413 140534394648384 print_helper.py:59] [92mTensor("add_14/add:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:00.595716 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
W0830 20:47:00.596215 140534394648384 print_helper.py:77] [93mTensor("activation_45/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
W0830 20:47:00.596750 140534394648384 print_helper.py:77] [93m>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> identity block[0m
I0830 20:47:00.597273 140534394648384 print_helper.py:59] [92mTensor("activation_45/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:00.702299 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2a/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:01.109163 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2a/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:01.117483 140534394648384 print_helper.py:59] [92mTensor("activation_46/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:01.221860 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2b/BiasAdd:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:01.626919 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2b/cond/Identity:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:01.635453 140534394648384 print_helper.py:59] [92mTensor("activation_47/Relu:0", shape=(None, None, None, 512), dtype=float32)[0m
I0830 20:47:01.748663 140534394648384 print_helper.py:59] [92mTensor("res5c_branch2c/BiasAdd:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:02.204741 140534394648384 print_helper.py:59] [92mTensor("bn5c_branch2c/cond/Identity:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:02.215928 140534394648384 print_helper.py:59] [92mTensor("add_15/add:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:02.225827 140534394648384 print_helper.py:59] [92mTensor("activation_48/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
W0830 20:47:02.226434 140534394648384 print_helper.py:77] [93mTensor("activation_48/Relu:0", shape=(None, None, None, 2048), dtype=float32)[0m
I0830 20:47:02.226970 140534394648384 east_model.py:252] Shape of f_0 : (None, None, None, 2048)
I0830 20:47:02.227480 140534394648384 east_model.py:252] Shape of f_1 : (None, None, None, 1024)
I0830 20:47:02.227984 140534394648384 east_model.py:252] Shape of f_2 : (None, None, None, 512)
I0830 20:47:02.228488 140534394648384 east_model.py:252] Shape of f_3 : (None, None, None, 256)
I0830 20:47:02.302483 140534394648384 east_model.py:271] Shape of h_0 : (None, None, None, 2048), g_0 : (None, None, None, 2048)
I0830 20:47:02.681143 140534394648384 east_model.py:271] Shape of h_1 : (None, None, None, 128), g_1 : (None, None, None, 128)
I0830 20:47:03.083263 140534394648384 east_model.py:271] Shape of h_2 : (None, None, None, 64), g_2 : (None, None, None, 64)
I0830 20:47:03.545666 140534394648384 east_model.py:271] Shape of h_3 : (None, None, None, 32), g_3 : (None, None, None, 32)
I0830 20:47:03.997749 140534394648384 estimator.py:1147] Done calling model_fn.
W0830 20:47:03.998592 140534394648384 deprecation.py:323] From /home/mageswarand/.conda/envs/default/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
I0830 20:47:04.000495 140534394648384 export_utils.py:170] Signatures INCLUDED in export for Classify: None
I0830 20:47:04.000986 140534394648384 export_utils.py:170] Signatures INCLUDED in export for Regress: None
I0830 20:47:04.001450 140534394648384 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict', 'serving_default']
I0830 20:47:04.001905 140534394648384 export_utils.py:170] Signatures INCLUDED in export for Train: None
I0830 20:47:04.002354 140534394648384 export_utils.py:170] Signatures INCLUDED in export for Eval: None
2019-08-30 20:47:04.003368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:47:04.004055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:01:00.0
2019-08-30 20:47:04.004101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-08-30 20:47:04.004117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-08-30 20:47:04.004132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-08-30 20:47:04.004148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-08-30 20:47:04.004163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-08-30 20:47:04.004179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-08-30 20:47:04.004194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-08-30 20:47:04.004260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:47:04.004987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:47:04.005626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-08-30 20:47:04.005649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-30 20:47:04.005655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-08-30 20:47:04.005660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-08-30 20:47:04.005796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:47:04.006479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-30 20:47:04.007137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0830 20:47:08.060463 140534394648384 saver.py:1284] Restoring parameters from /opt/tf_issue_32052/data/east_net/model.ckpt-30
I0830 20:47:08.750738 140534394648384 builder_impl.py:662] Assets added to graph.
I0830 20:47:08.751270 140534394648384 builder_impl.py:457] No assets to write.
I0830 20:47:10.740417 140534394648384 builder_impl.py:422] SavedModel written to: /opt/tf_issue_32052/data/east_net/export/temp-b'1567178193'/saved_model.pb
   107  18913.9 MiB  18913.9 MiB   @profile
   108                             def serving_input_receiver_fn():
   109  18913.9 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   110                                     inputs = {
   111  18913.9 MiB      0.0 MiB               "images": tf.compat.v1.placeholder(tf.float32, [None, None, None, 3]),
   112                                     }
   113                                 else:
   114                                     inputs = {
   115                                         "data": tf.compat.v1.placeholder(tf.float32, [None, 1, 250]),
   116                                     }
   117  18913.9 MiB      0.0 MiB       return tf.estimator.export.ServingInputReceiver(inputs, inputs)


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
   120  18913.8 MiB  18913.8 MiB   @profile
   121                             def export_model(estimator, model_export_path):
   122  18913.8 MiB      0.0 MiB       logging.info("Saving model to =======> {}".format(model_export_path))
   123  18913.8 MiB      0.0 MiB       if not os.path.exists(model_export_path):
   124  18913.8 MiB      0.0 MiB           os.makedirs(model_export_path)
   125  18913.8 MiB      0.0 MiB       estimator.export_saved_model(
   126  18913.8 MiB      0.0 MiB           model_export_path,
   127  18974.1 MiB     60.3 MiB           serving_input_receiver_fn=serving_input_receiver_fn)


Filename: tf_memory_test.py

Line #    Mem usage    Increment   Line Contents
================================================
   130    301.1 MiB    301.1 MiB   @profile
   131                             def main():
   132    301.1 MiB      0.0 MiB       memory_used = []
   133    301.1 MiB      0.0 MiB       process = psutil.Process(os.getpid())
   134    301.1 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   135    321.0 MiB     19.9 MiB           generate_image_tf_records(number_files=5, out_dir=TRAIN_DATA)
   136    316.2 MiB      0.0 MiB           generate_image_tf_records(number_files=2, out_dir=VAL_DATA)
   137                                 else:
   138                                     generate_numpy_tf_records(number_files=10, out_dir=TRAIN_DATA)
   139                                     generate_numpy_tf_records(number_files=3, out_dir=VAL_DATA)
   140                             
   141                                 # print(dataset_to_iterator(data_path=TRAIN_DATA))
   142                             
   143    316.2 MiB      0.0 MiB       if EAST_IMAGE_TEST:
   144    316.2 MiB      0.0 MiB           model = EASTTFModel(model_root_directory="store")
   145                                 else:
   146                                     model = NNet()
   147                             
   148    316.2 MiB      0.0 MiB       estimator = tf.estimator.Estimator(model_fn=model, config=_init_tf_config(), params=None)
   149    316.2 MiB      0.0 MiB       memory_usage_psutil()
   150    316.2 MiB      0.0 MiB       print('objgraph growth list')
   151    316.2 MiB      0.0 MiB       objgraph.show_growth(limit=50)
   152                                 # print(objgraph.get_leaking_objects())
   153                             
   154  18910.1 MiB      0.0 MiB       for epoch in tqdm(range(NUM_EPOCHS)):
   155                             
   156  13731.7 MiB      0.0 MiB           print("\n\n\n\n\n\n")
   157  13731.7 MiB      0.0 MiB           print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch")
   158  13731.7 MiB      0.0 MiB           memory_usage_psutil()
   159  13731.7 MiB      0.0 MiB           memory_used.append(process.memory_info()[0] / float(2 ** 20))
   160  13731.7 MiB      0.0 MiB           print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Training")
   161  16514.7 MiB   5412.2 MiB           train(estimator=estimator)
   162  16514.7 MiB      0.0 MiB           print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Evaluating")
   163  18909.6 MiB   2663.0 MiB           evaluate(estimator=estimator)
   164  18909.6 MiB      0.0 MiB           print('objgraph growth list after iteration {}'.format(epoch))
   165  18910.1 MiB      0.5 MiB           objgraph.show_growth(limit=50)
   166                             
   167  18912.6 MiB      2.6 MiB       plt.plot(memory_used)
   168  18912.6 MiB      0.0 MiB       plt.title('Evolution of memory')
   169  18912.6 MiB      0.0 MiB       plt.xlabel('iteration')
   170  18912.6 MiB      0.0 MiB       plt.ylabel('memory used (MB)')
   171  18913.4 MiB      0.8 MiB       plt.savefig("memory_usage.png")
   172  18913.8 MiB      0.4 MiB       plt.show()
   173                             
   174  18913.8 MiB      0.0 MiB       print_error(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> New Epoch")
   175  18974.1 MiB     60.3 MiB       export_model(estimator=estimator, model_export_path=EXPORT_DIR)
   176                             
   177  19965.7 MiB    991.6 MiB       (objgraph.get_leaking_objects())


Top 100 lines
#1: util/tf_stack.py:195: 569286.2 KiB
    ret.append((filename, lineno, name, frame_globals, func_start_lineno))
#2: framework/function.py:1090: 207405.9 KiB
    argnames = [arg.name for arg in fdef.signature.input_arg]
#3: framework/function.py:1097: 194813.8 KiB
    out_names = [arg.name for arg in fdef.signature.output_arg]
#4: util/tf_stack.py:182: 132537.0 KiB
    lineno = f.f_lineno
#5: util/tf_stack.py:187: 129318.6 KiB
    func_start_lineno = co.co_firstlineno
#6: framework/ops.py:393: 62060.0 KiB
    self._consumers = []
#7: framework/ops.py:5268: 44040.8 KiB
    def get_default(self):
#8: framework/ops.py:5455: 40298.5 KiB
    def get_default(self):
#9: framework/function.py:281: 37424.6 KiB
    self._whitelisted_stateful_ops = set()
#10: framework/ops.py:1713: 30274.7 KiB
    self._graph = g
#11: framework/function.py:271: 28069.3 KiB
    self._func = func
#12: python/pywrap_tensorflow_internal.py:44: 22042.4 KiB
    self.__dict__[name] = value
#13: util/tf_inspect.py:279: 19689.1 KiB
    call_args = named.copy()
#14: framework/ops.py:1882: 17834.2 KiB
    return c_api.TF_OperationName(self._c_op)
#15: framework/ops.py:1786: 15605.9 KiB
    for i, output_type in enumerate(output_types)
#16: framework/function.py:1092: 15587.0 KiB
    dtypes.as_dtype(arg.type) for arg in fdef.signature.input_arg)
#17: framework/function.py:1130: 14702.5 KiB
    funcs = {fdef.signature.name: fdef for fdef in lib.function}
#18: framework/ops.py:3292: 14113.8 KiB
    self._functions[compat.as_str(name)] = function
#19: framework/function.py:1093: 13662.9 KiB
    func_name = fdef.signature.name
#20: python/pywrap_tensorflow_internal.py:39: 13615.4 KiB
    def _swig_setattr_nondynamic(self, class_type, name, value, static=1):
#21: framework/ops.py:4180: 12656.9 KiB
    name_key = name.lower()
#22: framework/ops.py:5861: 11984.7 KiB
    @tf_export(v1=["get_default_graph"])
#23: framework/function.py:289: 11939.9 KiB
    self._sub_functions = {}  # Constructed with _definition or _c_func
#24: framework/function.py:306: 10752.4 KiB
    for i in range(len(input_types))]
#25: framework/ops.py:4948: 10693.1 KiB
    device_functions_outer_to_inner = list(reversed(device_functions))
#26: framework/ops.py:4947: 10692.8 KiB
    device_functions = [spec.function for spec in user_device_specs]
#27: eager/backprop.py:146: 10423.5 KiB
    results, name)
#28: framework/ops.py:2170: 10076.7 KiB
    self._inputs_val = Operation._InputList(retval)
#29: framework/c_api_util.py:186: 10005.2 KiB
    ret = c_api.TF_Output()
#30: python/pywrap_tensorflow_internal.py:58: 9641.4 KiB
    def _swig_setattr(self, class_type, name, value):
#31: python3.7/contextlib.py:237: 9538.3 KiB
    @wraps(func)
#32: framework/ops.py:3429: 9486.4 KiB
    op_def=op_def)
#33: framework/function.py:1103: 9356.2 KiB
    result._c_func = c_api_util.ScopedTFFunction(c_func)
#34: framework/function.py:1099: 9356.2 KiB
    python_grad_func, out_names)
#35: framework/ops.py:4194: 9342.9 KiB
    self._names_in_use[name_key] = 1
#36: framework/tensor_shape.py:776: 9292.4 KiB
    self._dims = [as_dimension(d) for d in dims_iter]
#37: framework/ops.py:2166: 8750.1 KiB
    self.graph._get_tensor_by_tf_output(tf_output)
#38: python/pywrap_tensorflow_internal.py:1458: 8575.9 KiB
    this = _pywrap_tensorflow_internal.new_TF_Output()
#39: framework/tensor_shape.py:193: 8414.9 KiB
    self._value = int(value)
#40: framework/ops.py:1610: 8130.4 KiB
    c_op = c_api.TF_FinishOperation(op_desc)
#41: framework/function.py:1102: 8019.6 KiB
    c_func = c_api.TF_FunctionImportFunctionDef(serialized)
#42: framework/ops.py:2163: 7873.6 KiB
    tf_outputs = c_api.GetOperationInputs(self._c_op)
#43: util/tf_inspect.py:284: 7833.2 KiB
    call_args.update(dict(zip(remaining_positionals, positional)))
#44: framework/traceable_stack.py:75: 7689.6 KiB
    return self.__class__(None, filename=self.filename, lineno=self.lineno)
#45: framework/ops.py:2142: 7274.2 KiB
    self._inputs = inputs
#46: framework/c_api_util.py:85: 6875.7 KiB
    self.func = func
#47: framework/ops.py:1785: 6729.8 KiB
    Tensor(self, i, output_type)
#48: framework/tensor_shape.py:718: 6703.9 KiB
    return Dimension(value)
#49: framework/ops.py:497: 6502.1 KiB
    return tensor_shape.TensorShape(shape_vector)
#50: python/pywrap_tensorflow_internal.py:1444: 5922.2 KiB
    __setattr__ = lambda self, name, value: _swig_setattr(self, TF_Output, name, value)
#51: python3.7/contextlib.py:82: 5875.0 KiB
    self.gen = func(*args, **kwds)
#52: framework/ops.py:3025: 5751.8 KiB
    self._nodes_by_name[op.name] = op
#53: framework/ops.py:3024: 5751.8 KiB
    self._nodes_by_id[op._id] = op
#54: framework/ops.py:4189: 5581.6 KiB
    name_key = "%s_%d" % (base_name_key, i)
#55: framework/traceable_stack.py:31: 5570.2 KiB
    self.obj = obj
#56: framework/ops.py:1781: 5248.8 KiB
    c_api.TF_OperationOutputType(c_api_util.tf_output(self._c_op, i))
#57: framework/ops.py:252: 5120.0 KiB
    return c_api.TFE_Py_UID()
#58: python/pywrap_tensorflow_internal.py:62: 4772.5 KiB
    def _swig_getattr_nondynamic(self, class_type, name, static=1):
#59: framework/ops.py:2167: 4578.2 KiB
    for tf_output in tf_outputs
#60: python/pywrap_tensorflow_internal.py:73: 4246.2 KiB
    def _swig_getattr(self, class_type, name):
#61: python3.7/inspect.py:1153: 4026.7 KiB
    defaults += (param.default,)
#62: util/object_identity.py:160: 4014.7 KiB
    self._storage = set([self._wrap_key(obj) for obj in list(*args)])
#63: framework/ops.py:2822: 3694.8 KiB
    self._lock = threading.RLock()
#64: framework/ops.py:496: 3572.2 KiB
    shape_vector = [None if d == -1 else d for d in shape_vector]
#65: python3.7/inspect.py:158: 3503.5 KiB
    def isfunction(object):
#66: framework/dtypes.py:87: 3440.6 KiB
    @property
#67: framework/ops.py:418: 3253.1 KiB
    self._name = "%s:%d" % (self._op.name, self._value_index)
#68: framework/ops.py:3808: 3225.9 KiB
    self._next_id_counter += 1
#69: framework/func_graph.py:372: 3067.7 KiB
    graph._distribution_strategy_stack)
#70: framework/function.py:1170: 3040.7 KiB
    ready.extend(funcs[f] for f in grad_to_funcs[name])
#71: framework/ops.py:3970: 3022.4 KiB
    return list(collection)
#72: python/pywrap_tensorflow_internal.py:1446: 2966.2 KiB
    __getattr__ = lambda self, name: _swig_getattr(self, TF_Output, name)
#73: python3.7/enum.py:283: 2815.5 KiB
    def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1):
#74: python3.7/threading.py:348: 2815.3 KiB
    waiters_to_notify = _deque(_islice(all_waiters, n))
#75: framework/ops.py:4964: 2636.0 KiB
    snapshot.append(obj_copy)
#76: tracking/base.py:591: 2582.7 KiB
    self._self_unconditional_checkpoint_dependencies = []
#77: python3.7/enum.py:525: 2423.1 KiB
    def __new__(cls, value):
#78: python3.7/contextlib.py:81: 2380.5 KiB
    def __init__(self, func, args, kwds):
#79: ops/resource_variable_ops.py:399: 2358.7 KiB
    self._distribute_strategy = distribute_strategy
#80: python3.7/linecache.py:137: 2257.5 KiB
    lines = fp.readlines()
#81: framework/ops.py:2838: 2225.4 KiB
    self._thread_local = threading.local()
#82: framework/ops.py:2400: 2189.4 KiB
    return list(getattr(x.list, f))
#83: framework/tensor_shape.py:184: 1996.5 KiB
    def __init__(self, value):
#84: python3.7/functools.py:60: 1843.4 KiB
    getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
#85: util/tf_inspect.py:287: 1712.7 KiB
    for arg, value in zip(argspec.args[-default_count:], argspec.defaults):
#86: eager/function.py:443: 1704.4 KiB
    self._output_types = [o.type for o in self.signature.output_arg]
#87: eager/context.py:1576: 1669.2 KiB
    def context_safe():
#88: framework/ops.py:4021: 1667.5 KiB
    @property
#89: util/deprecation.py:480: 1662.4 KiB
    named_args = tf_inspect.getcallargs(func, *args, **kwargs)
#90: python3.7/inspect.py:2465: 1497.1 KiB
    def __init__(self, name, kind, *, default=_empty, annotation=_empty):
#91: framework/tensor_shape.py:753: 1449.3 KiB
    self._dims = None
#92: util/lock_util.py:108: 1409.8 KiB
    c > 0 for g, c in enumerate(self._group_member_counts) if g != group_id)
#93: framework/ops.py:492: 1405.6 KiB
    c_graph, self._as_tf_output())
#94: framework/func_graph.py:639: 1403.3 KiB
    self._captures[ops.tensor_id(tensor)] = (tensor, placeholder)
#95: framework/tensor_shape.py:1181: 1330.4 KiB
    size=-1 if d.value is None else d.value) for d in self._dims
#96: eager/function.py:433: 1231.8 KiB
    self.name = compat.as_bytes(function_def.signature.name)
#97: framework/ops.py:2879: 1218.7 KiB
    self._unfetchable_ops = set()
#98: framework/func_graph.py:256: 1217.1 KiB
    self._saving_errors = set()
#99: framework/func_graph.py:196: 1217.1 KiB
    self.control_captures = set()
#100: framework/ops.py:4025: 1205.1 KiB
    self._thread_local._name_stack = ""
2442 other: 77377.6 KiB
2442 other: 75.6 MiB
Total allocated size: 2115144.8 KiB
Total allocated size: 2065.6 MiB
